{
  "last_updated": "2025-03-14T13:00:05.424383",
  "author": {
    "name": "Johannes C. Paetzold",
    "affiliation": "Imperial College London",
    "interests": [
      "Machine Learning",
      "Geometric Deep Learning",
      "Generative Models",
      "Biomedical Image Analysis"
    ]
  },
  "categories": {
    "mri": "MRI",
    "ct": "CT",
    "ultrasound": "Ultrasound",
    "x-ray": "X-ray",
    "pet": "PET",
    "histology": "Histology",
    "microscopy": "Microscopy",
    "gnn": "GNN",
    "generative": "Generative AI",
    "topology": "Topology",
    "segmentation": "Segmentation",
    "reconstruction": "Reconstruction",
    "detection": "Detection",
    "registration": "Registration",
    "classification": "Classification"
  },
  "publications": [
    {
      "id": "pub001",
      "title": "Machine learning analysis of whole mouse brain vasculature",
      "authors": "Mihail Ivilinov Todorov* and Johannes Christian Paetzold* and Oliver Schoppe and Giles Tetteh and Suprosanna Shit and Velizar Efremov and Katalin Todorov-Völgyi and Marco Düring and Martin Dichgans and Marie Piraud and Bjoern Menze and Ali Ertürk",
      "year": 2020,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Tissue clearing methods enable the imaging of biological specimens without sectioning. However, reliable and scalable analysis of large imaging datasets in three dimensions remains a challenge. Here we developed a deep learning-based framework to quantify and analyze brain vasculature, named Vessel Segmentation & Analysis Pipeline (VesSAP). Our pipeline uses a convolutional neural network (CNN) with a transfer learning approach for segmentation and achieves human-level accuracy. By using VesSAP, we analyzed the vascular features of whole C57BL/6J, CD1 and BALB/c mouse brains at the micrometer scale after registering them to the Allen mouse brain atlas. We report evidence of secondary intracranial collateral vascularization in CD1 mice and find reduced vascularization of the brainstem in comparison to the cerebrum. Thus, VesSAP enables unbiased and scalable quantifications of the …",
      "url": "https://www.nature.com/articles/s41592-020-0792-1",
      "scholar_link": "/scholar?hl=en&cites=6119225247391437016,10746172399246019807,5699954493115985367,6133801038298067141,10611529803718330026,17522700883482523229",
      "citations": 349,
      "pdf_link": "",
      "categories": [
        "microscopy",
        "mri",
        "generative",
        "ct",
        "segmentation",
        "reconstruction",
        "detection",
        "registration",
        "x-ray",
        "pet",
        "histology",
        "topology"
      ],
      "primary_category": "microscopy",
      "thumbnail": "images/publications/thumbnails/machine_learning_analysis_of_w.jpg",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub002",
      "title": "clDice - a Topology-Preserving Loss Function for Tubular Structure Segmentation",
      "authors": "Suprosanna Shit* and Johannes C Paetzold* and Anjany Sekuboyina and Andrey Zhylka and Ivan Ezhov and Alexander Unger and Josien PW Pluim and Giles Tetteh and Bjoern H Menze",
      "year": 2021,
      "venue": "CVPR",
      "venue_tag": null,
      "doi": null,
      "abstract": "",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shit_clDice_-_A_Novel_Topology-Pr[…]ng_Loss_Function_for_Tubular_Structure_CVPR_2021_paper.pdf",
      "scholar_link": "/scholar?hl=en&cites=17149814151594930474,11561599168494704613,13174810049061567829,16632085098506993449,10817242860175646475",
      "citations": 329,
      "pdf_link": "",
      "categories": [
        "topology",
        "ct",
        "segmentation"
      ],
      "primary_category": "topology",
      "thumbnail": "images/publications/manual_added/clDice.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub005",
      "title": "An automatic multi-tissue human fetal brain segmentation benchmark using the fetal tissue annotation dataset",
      "authors": "Kelly Payette and Priscille de Dumast and Hamza Kebiri and Ivan Ezhov and Johannes C Paetzold and Suprosanna Shit and Asim Iqbal and Romesa Khan and Raimund Kottke and Patrice Grehten and Hui Ji and Levente Lanczi and Marianna Nagy and Monika Beresova and Thi Dao Nguyen and Giancarlo Natalucci and Theofanis Karayannis and Bjoern Menze and Meritxell Bach Cuadra and Andras Jakab",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "It is critical to quantitatively analyse the developing human fetal brain in order to fully understand neurodevelopment in both normal fetuses and those with congenital disorders. To facilitate this analysis, automatic multi-tissue fetal brain segmentation algorithms are needed, which in turn requires open datasets of segmented fetal brains. Here we introduce a publicly available dataset of 50 manually segmented pathological and non-pathological fetal magnetic resonance brain volume reconstructions across a range of gestational ages (20 to 33 weeks) into 7 different tissue categories (external cerebrospinal fluid, grey matter, white matter, ventricles, cerebellum, deep grey matter, brainstem/spinal cord). In addition, we quantitatively evaluate the accuracy of several automatic multi-tissue segmentation algorithms of the developing human fetal brain. Four research groups participated, submitting a total of 10 algorithms …",
      "url": "https://www.nature.com/articles/s41597-021-00946-3",
      "scholar_link": "/scholar?hl=en&cites=16424824752438866090,5310378280287170908,2923815062559667367",
      "citations": 136,
      "pdf_link": "",
      "categories": [
        "mri",
        "segmentation",
        "reconstruction",
        "classification",
        "ct",
        "generative",
        "registration",
        "ultrasound",
        "pet",
        "histology",
        "topology"
      ],
      "primary_category": "mri",
      "thumbnail": "images/publications/thumbnails/an_automatic_multi_tissue_huma.jpg",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub006",
      "title": "DiamondGAN: Unified Multi-modal Generative Adversarial Networks for MRI Sequences Synthesis",
      "authors": "Bjoern Menze Hongwei Li* and Johannes C. Paetzold* and Anjany Sekuboyina and Florian Kofler and Jianguo Zhang and Jan S. Kirschke and Benedikt Wiestler",
      "year": 2019,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-32251-9_87",
      "scholar_link": "https://link.springer.com/chapter/10.1007/978-3-030-32251-9_87",
      "citations": 103,
      "pdf_link": "",
      "categories": [
        "generative",
        "mri"
      ],
      "primary_category": "generative",
      "thumbnail": "images/publications/manual_added/Diamond_GAN.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub008",
      "title": "Shape-aware complementary-task learning for multi-organ segmentation",
      "authors": "Fernando Navarro and Suprosanna Shit and Ivan Ezhov and Johannes Paetzold and Andrei Gafita and Jan C Peeken and Stephanie E Combs and Bjoern H Menze",
      "year": 2019,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": " Multi-organ segmentation in whole-body computed tomography (CT) is a constant pre-processing step which finds its application in organ-specific image retrieval, radiotherapy planning, and interventional image analysis. We address this problem from an organ-specific shape-prior learning perspective. We introduce the idea of complementary-task learning to enforce shape-prior leveraging the existing target labels. We propose two complementary-tasks namely (i) distance map regression and (ii) contour map detection to explicitly encode the geometric properties of each organ. We evaluate the proposed solution on the public VISCERAL dataset containing CT scans of multiple organs. We report a significant improvement of overall dice score from 0.8849 to 0.9018 due to the incorporation of complementary-task learning. ",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-32692-0_71",
      "scholar_link": "/scholar?hl=en&cites=2320766223886508673,8803492960280914339",
      "citations": 80,
      "pdf_link": "",
      "categories": [
        "generative",
        "ct",
        "segmentation",
        "detection",
        "reconstruction",
        "registration",
        "classification",
        "mri",
        "histology"
      ],
      "primary_category": "generative",
      "thumbnail": "images/publications/thumbnails/shape_aware_complementary_task.jpg",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub010",
      "title": "Red-GAN: Attacking class imbalance via conditioned generation. Yet another medical imaging perspective.",
      "authors": "Ahmad B Qasim and Ivan Ezhov and Suprosanna Shit and Oliver Schoppe and Johannes C Paetzold and Anjany Sekuboyina and Florian Kofler and Jana Lipkova and Hongwei Li and Bjoern Menze",
      "year": 2020,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Exploiting learning algorithms under scarce data regimes is a limitation and a reality of the medical imaging field. In an attempt to mitigate the problem, we propose a data augmentation protocol based on generative adversarial networks. We condition the networks at a pixel-level (segmentation mask) and at a global-level information (acquisition environment or lesion type). Such conditioning provides immediate access to the image-label pairs while controlling global class specific appearance of the synthesized images. To stimulate synthesis of the features relevant for the segmentation task, an additional passive player in a form of segmentor is introduced into the the adversarial game. We validate the approach on two medical datasets: BraTS, ISIC. By controlling the class distribution through injection of synthetic images into the training set we achieve control over the accuracy levels of the datasets’ classes. The code is available at https://github. com/IvanEz/Red-GAN.",
      "url": "https://proceedings.mlr.press/v121/qasim20a.html",
      "scholar_link": "/scholar?hl=en&cites=5536340229917913220,12845540852451607806,4233070793909201698,16093168992549147682,6915409880656328665",
      "citations": 74,
      "pdf_link": "",
      "categories": [
        "generative",
        "ct",
        "segmentation"
      ],
      "primary_category": "generative",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub012",
      "title": "Relationformer: A Unified Framework for Image-to-Graph Generation",
      "authors": "Suprosanna Shit and Rajat Koner and Bastian Wittmann and Johannes Paetzold and Ivan Ezhov and Hongwei Li and Jiazhen Pan and Sahand Sharifzadeh and Georgios Kaissis and Volker Tresp and Bjoern Menze",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "A comprehensive representation of an image requires understanding objects and their mutual relationship, especially in image-to-graph generation, e.g., road network extraction, blood-vessel network extraction, or scene graph generation. Traditionally, image-to-graph generation is addressed with a two-stage approach consisting of object detection followed by a separate relation prediction, which prevents simultaneous object-relation interaction. This work proposes a unified one-stage transformer-based framework, namely Relationformer that jointly predicts objects and their relations. We leverage direct set-based object prediction and incorporate the interaction among the objects to learn an object-relation representation jointly. In addition to existing [obj]-tokens, we propose a novel learnable token, namely [rln]-token. Together with [obj]-tokens, [rln]-token exploits local and global semantic reasoning in an image …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19836-6_24",
      "scholar_link": "/scholar?hl=en&cites=16116173940654779023",
      "citations": 65,
      "pdf_link": "",
      "categories": [
        "detection",
        "ct"
      ],
      "primary_category": "detection",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub013",
      "title": "Topologically faithful image segmentation via induced matching of persistence barcodes",
      "authors": "Nico Stucki* and Johannes C Paetzold* and Suprosanna Shit* and Bjoern Menze and Ulrich Bauer",
      "year": 2023,
      "venue": "MICCAI",
      "venue_tag": "MICCAI",
      "doi": null,
      "abstract": "Segmentation models predominantly optimize pixel-overlap-based loss, an objective that is actually inadequate for many segmentation tasks. In recent years, their limitations fueled a growing interest in topology-aware methods, which aim to recover the topology of the segmented structures. However, so far, existing methods only consider global topological properties, ignoring the need to preserve topological features spatially, which is crucial for accurate segmentation. We introduce the concept of induced matchings from persistent homology to achieve a spatially correct matching between persistence barcodes in a segmentation setting. Based on this concept, we define the Betti matching error as an interpretable, topologically and feature-wise accurate metric for image segmentations, which resolves the limitations of the Betti number error. Our Betti matching error is differentiable and efficient to use as a loss function. We demonstrate that it improves the topological performance of segmentation networks significantly across six diverse datasets while preserving the performance with respect to traditional scores. Our code is publicly available (https://github. com/nstucki/Betti-matching/).",
      "url": "https://proceedings.mlr.press/v202/stucki23a",
      "scholar_link": "/scholar?hl=en&cites=15109376508076966914,10163770910035407110",
      "citations": 52,
      "pdf_link": "",
      "categories": [
        "topology",
        "segmentation",
        "ct"
      ],
      "primary_category": "topology",
      "thumbnail": "images/publications/manual_added/Betti.png  ",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub014",
      "title": "Anthropogenic CO2 emissions assessment of Nile Delta using XCO2 and SIF data from OCO-2 satellite",
      "authors": "Ankit Shekhar and Jia Chen and Johannes C Paetzold and Florian Dietrich and Xinxu Zhao and Shrutilipi Bhattacharjee and Veronika Ruisinger and Steven C Wofsy",
      "year": 2020,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We estimate CO 2 emissions from the Nile Delta region of Egypt, using over five years of column-averaged CO 2 dry air mole fraction (XCO 2) data from the NASA's OCO-2 satellite. The Nile Delta has significant anthropogenic emissions of CO 2 from urban areas and irrigated farming. It is surrounded by the Sahara desert and the Mediterranean Sea, minimizing the confounding influence of CO 2 sources in surrounding areas. We compiled the observed spatial and temporal variations of XCO 2 in the Nile Delta region (XCO 2, del), and found that values for XCO 2, del were on average 1.1 ppm higher than XCO 2, des (mean XCO 2 in desert area). We modelled the expected enhancements of XCO 2 over the Nile Delta based on two global CO 2 emission inventories, EDGAR and ODIAC. Modelled XCO 2 enhancements were much lower, indicating underestimation of CO 2 emissions in the Nile Delta region by mean …",
      "url": "https://iopscience.iop.org/article/10.1088/1748-9326/ab9cfe/meta",
      "scholar_link": "/scholar?hl=en&cites=8378738565440078971",
      "citations": 50,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub016",
      "title": "Differentially private graph neural networks for whole-graph classification",
      "authors": "Tamara T Mueller and Johannes C Paetzold and Chinmay Prabhakar and Dmitrii Usynin and Daniel Rueckert and Georgios Kaissis",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Graph Neural Networks (GNNs) have established themselves as state-of-the-art for many machine learning applications such as the analysis of social and medical networks. Several among these datasets contain privacy-sensitive data. Machine learning with differential privacy is a promising technique to allow deriving insight from sensitive data while offering formal guarantees of privacy protection. However, the differentially private training of GNNs has so far remained under-explored due to the challenges presented by the intrinsic structural connectivity of graphs. In this work, we introduce a framework for differential private graph-level classification. Our method is applicable to graph deep learning on multi-graph datasets and relies on differentially private stochastic gradient descent (DP-SGD). We show results on a variety of datasets and evaluate the impact of different GNN architectures and training …",
      "url": "https://ieeexplore.ieee.org/abstract/document/9980390/",
      "scholar_link": "/scholar?hl=en&cites=9603293110171264030,12712994124958958466",
      "citations": 44,
      "pdf_link": "",
      "categories": [
        "gnn",
        "classification",
        "ct"
      ],
      "primary_category": "gnn",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub017",
      "title": "Whole brain vessel graphs: A dataset and benchmark for graph learning and neuroscience",
      "authors": "Johannes C Paetzold and Julian McGinnis and Suprosanna Shit and Ivan Ezhov and Paul Büschl and Chinmay Prabhakar and Anjany Sekuboyina and Mihail Todorov and Georgios Kaissis and Ali Ertürk and Stephan Günnemann",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Biological neural networks define the brain function and intelligence of humans and other mammals, and form ultra-large, spatial, structured graphs. Their neuronal organization is closely interconnected with the spatial organization of the brain's microvasculature, which supplies oxygen to the neurons and builds a complementary spatial graph. This vasculature (or the vessel structure) plays an important role in neuroscience; for example, the organization of (and changes to) vessel structure can represent early signs of various pathologies, e.g. Alzheimer's disease or stroke. Recently, advances in tissue clearing have enabled whole brain imaging and segmentation of the entirety of the mouse brain's vasculature.  Building on these advances in imaging, we are presenting an extendable dataset of whole-brain vessel graphs based on specific imaging protocols. Specifically, we extract vascular graphs using a refined graph extraction scheme leveraging the volume rendering engine Voreen and provide them in an accessible and adaptable form through the OGB and PyTorch Geometric dataloaders. Moreover, we benchmark numerous state-of-the-art graph learning algorithms on the biologically relevant tasks of vessel prediction and vessel classification using the introduced vessel graph dataset.  Our work paves a path towards advancing graph learning research into the field of neuroscience. Complementarily, the presented dataset raises challenging graph learning research questions for the machine learning community, in terms of incorporating biological priors into learning algorithms, or in scaling these algorithms to handle sparse,spatial graphs …",
      "url": "https://openreview.net/forum?id=jpwGODt2Av",
      "scholar_link": "/scholar?hl=en&cites=9586798430584881548,15347679667236637325,123798595203799053",
      "citations": 42,
      "pdf_link": "",
      "categories": [
        "ct",
        "generative",
        "segmentation",
        "classification"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub020",
      "title": "SoK: Differential privacy on graph-structured data",
      "authors": "Tamara T Mueller and Dmitrii Usynin and Johannes C Paetzold and Daniel Rueckert and Georgios Kaissis",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "In this work, we study the applications of differential privacy (DP) in the context of graph-structured data. We discuss the formulations of DP applicable to the publication of graphs and their associated statistics as well as machine learning on graph-based data, including graph neural networks (GNNs). The formulation of DP in the context of graph-structured data is difficult, as individual data points are interconnected (often non-linearly or sparsely). This connectivity complicates the computation of individual privacy loss in differentially private learning. The problem is exacerbated by an absence of a single, well-established formulation of DP in graph settings. This issue extends to the domain of GNNs, rendering private machine learning on graph-structured data a challenging task. A lack of prior systematisation work motivated us to study graph-based learning from a privacy perspective. In this work, we systematise different formulations of DP on graphs, discuss challenges and promising applications, including the GNN domain. We compare and separate works into graph analysis tasks and graph learning tasks with GNNs. Finally, we conclude our work with a discussion of open questions and potential directions for further research in this area.",
      "url": "https://arxiv.org/abs/2203.09205",
      "scholar_link": "/scholar?hl=en&cites=9788841028506383538",
      "citations": 30,
      "pdf_link": "",
      "categories": [
        "gnn",
        "ct"
      ],
      "primary_category": "gnn",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub021",
      "title": "Synthetic optical coherence tomography angiographs for detailed retinal vessel segmentation without human annotations",
      "authors": "Linus Kreitner and Johannes C Paetzold and Nikolaus Rauch and Chen Chen and Ahmed M Hagag and Alaa E Fayed and Sobha Sivaprasad and Sebastian Rausch and Julian Weichsel and Bjoern H Menze and Matthias Harders and Benjamin Knier and Daniel Rueckert and Martin J Menten",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Optical coherence tomography angiography (OCTA) is a non-invasive imaging modality that can acquire high-resolution volumes of the retinal vasculature and aid the diagnosis of ocular, neurological and cardiac diseases. Segmenting the visible blood vessels is a common first step when extracting quantitative biomarkers from these images. Classical segmentation algorithms based on thresholding are strongly affected by image artifacts and limited signal-to-noise ratio. The use of modern, deep learning-based segmentation methods has been inhibited by a lack of large datasets with detailed annotations of the blood vessels. To address this issue, recent work has employed transfer learning, where a segmentation network is trained on synthetic OCTA images and is then applied to real data. However, the previously proposed simulations fail to faithfully model the retinal vasculature and do not provide effective …",
      "url": "https://ieeexplore.ieee.org/abstract/document/10400503/",
      "scholar_link": "/scholar?hl=en&cites=15798049750933099252,10006511146387669543",
      "citations": 29,
      "pdf_link": "",
      "categories": [
        "segmentation",
        "ct",
        "classification"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub022",
      "title": "Benchmarking the cow with the topcow challenge: Topology-aware anatomical segmentation of the circle of willis for cta and mra",
      "authors": "Kaiyuan Yang and Fabio Musio and Yihui Ma and Norman Juchler and Johannes C Paetzold and Rami Al-Maskari and Luciano Höher and Hongwei Bran Li and Ibrahim Ethem Hamamci and Anjany Sekuboyina and Suprosanna Shit and Houjing Huang and Chinmay Prabhakar and Ezequiel de la Rosa and Diana Waldmannstetter and Florian Kofler and Fernando Navarro and Martin Menten and Ivan Ezhov and Daniel Rueckert and Iris Vos and Ynte Ruigrok and Birgitta Velthuis and Hugo Kuijf and Julien Hämmerli and Catherine Wurster and Philippe Bijlenga and Laura Westphal and Jeroen Bisschop and Elisa Colombo and Hakim Baazaoui and Andrew Makmur and James Hallinan and Bene Wiestler and Jan S Kirschke and Roland Wiest and Emmanuel Montagnon and Laurent Letourneau-Guillon and Adrian Galdran and Francesco Galati and Daniele Falcetta and Maria A Zuluaga and Chaolong Lin and Haoran Zhao and Zehan Zhang and Sinyoung Ra and Jongyun Hwang and Hyunjin Park and Junqiang Chen and Marek Wodzinski and Henning Müller and Pengcheng Shi and Wei Liu and Ting Ma and Cansu Yalçin and Rachika E Hamadache and Joaquim Salvi and Xavier Llado and Uma Maria Lal-Trehan Estrada and Valeriia Abramova and Luca Giancardo and Arnau Oliver and Jialu Liu and Haibin Huang and Yue Cui and Zehang Lin and Yusheng Liu and Shunzhi Zhu and Tatsat R Patel and Vincent M Tutino and Maysam Orouskhani and Huayu Wang and Mahmud Mossa-Basha and Chengcheng Zhu and Maximilian R Rokuss and Yannick Kirchhoff and Nico Disch and Julius Holzschuh and Fabian Isensee and Klaus Maier-Hein and Yuki Sato and Sven Hirsch and Susanne Wegener and Bjoern Menze",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "The Circle of Willis (CoW) is an important network of arteries connecting major circulations of the brain. Its vascular architecture is believed to affect the risk, severity, and clinical outcome of serious neuro-vascular diseases. However, characterizing the highly variable CoW anatomy is still a manual and time-consuming expert task. The CoW is usually imaged by two angiographic imaging modalities, magnetic resonance angiography (MRA) and computed tomography angiography (CTA), but there exist limited public datasets with annotations on CoW anatomy, especially for CTA. Therefore we organized the TopCoW Challenge in 2023 with the release of an annotated CoW dataset. The TopCoW dataset was the first public dataset with voxel-level annotations for thirteen possible CoW vessel components, enabled by virtual-reality (VR) technology. It was also the first large dataset with paired MRA and CTA from the …",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10793481/",
      "scholar_link": "/scholar?hl=en&cites=4228616984879154769",
      "citations": 28,
      "pdf_link": "",
      "categories": [
        "topology",
        "ct",
        "segmentation",
        "mri",
        "ultrasound",
        "generative",
        "gnn",
        "reconstruction",
        "detection"
      ],
      "primary_category": "topology",
      "thumbnail": "images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub023",
      "title": "Geometry-aware neural solver for fast Bayesian calibration of brain tumor models",
      "authors": "Ivan Ezhov and Tudor Mot and Suprosanna Shit and Jana Lipkova and Johannes C Paetzold and Florian Kofler and Chantal Pellegrini and Marcel Kollovieh and Fernando Navarro and Hongwei Li and Marie Metz and Benedikt Wiestler and Bjoern Menze",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Modeling of brain tumor dynamics has the potential to advance therapeutic planning. Current modeling approaches resort to numerical solvers that simulate the tumor progression according to a given differential equation. Using highly-efficient numerical solvers, a single forward simulation takes up to a few minutes of compute. At the same time, clinical applications of tumor modeling often imply solving an inverse problem, requiring up to tens of thousands of forward model evaluations when used for a Bayesian model personalization via sampling. This results in a total inference time prohibitively expensive for clinical translation. While recent data-driven approaches become capable of emulating physics simulation, they tend to fail in generalizing over the variability of the boundary conditions imposed by the patient-specific anatomy. In this paper, we propose a learnable surrogate for simulating tumor growth which …",
      "url": "https://ieeexplore.ieee.org/abstract/document/9656125/",
      "scholar_link": "/scholar?hl=en&cites=9197399204901403365,17051017873468874561",
      "citations": 25,
      "pdf_link": "",
      "categories": [
        "other"
      ],
      "primary_category": "other",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub025",
      "title": "Inferring the 3D standing spine posture from 2D radiographs",
      "authors": "Amirhossein Bayat and Anjany Sekuboyina and Johannes C Paetzold and Christian Payer and Darko Stern and Martin Urschler and Jan S Kirschke and Bjoern H Menze",
      "year": 2020,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "The treatment of degenerative spinal disorders requires an understanding of the individual spinal anatomy and curvature in 3D. An upright spinal pose (i.e. standing) under natural weight bearing is crucial for such bio-mechanical analysis. 3D volumetric imaging modalities (e.g. CT and MRI) are performed in patients lying down. On the other hand, radiographs are captured in an upright pose, but result in 2D projections. This work aims to integrate the two realms, i.e. it combines the upright spinal curvature from radiographs with the 3D vertebral shape from CT imaging for synthesizing an upright 3D model of spine, loaded naturally. Specifically, we propose a novel neural network architecture working vertebra-wise, termed TransVert, which takes orthogonal 2D radiographs and infers the spine’s 3D posture. We validate our architecture on digitally reconstructed radiographs, achieving a 3D reconstruction Dice …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-59725-2_75",
      "scholar_link": "/scholar?hl=en&cites=12225085260522728495",
      "citations": 24,
      "pdf_link": "",
      "categories": [
        "x-ray",
        "mri",
        "ct",
        "generative",
        "reconstruction"
      ],
      "primary_category": "x-ray",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub026",
      "title": "Physiology-based simulation of the retinal vasculature enables annotation-free segmentation of OCT angiographs",
      "authors": "Martin J Menten and Johannes C Paetzold and Alina Dima and Bjoern H Menze and Benjamin Knier and Daniel Rueckert",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": " Optical coherence tomography angiography (OCTA) can non-invasively image the eye’s circulatory system. In order to reliably characterize the retinal vasculature, there is a need to automatically extract quantitative metrics from these images. The calculation of such biomarkers requires a precise semantic segmentation of the blood vessels. However, deep-learning-based methods for segmentation mostly rely on supervised training with voxel-level annotations, which are costly to obtain.In this work, we present a pipeline to synthesize large amounts of realistic OCTA images with intrinsically matching ground truth labels; thereby obviating the need for manual annotation of training data. Our proposed method is based on two novel components: 1) a physiology-based simulation that models the various retinal vascular plexuses and 2) a suite of physics-based image augmentations that emulate the OCTA image …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-16452-1_32",
      "scholar_link": "/scholar?hl=en&cites=16670136572883903354",
      "citations": 22,
      "pdf_link": "",
      "categories": [
        "segmentation",
        "ct"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub027",
      "title": "SRflow: Deep learning based super-resolution of 4D-flow MRI data",
      "authors": "Suprosanna Shit and Judith Zimmermann and Ivan Ezhov and Johannes C Paetzold and Augusto F Sanches and Carolin Pirkl and Bjoern H Menze",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Exploiting 4D-flow magnetic resonance imaging (MRI) data to quantify hemodynamics requires an adequate spatio-temporal vector field resolution at a low noise level. To address this challenge, we provide a learned solution to super-resolve in vivo 4D-flow MRI data at a post-processing level. We propose a deep convolutional neural network (CNN) that learns the inter-scale relationship of the velocity vector map and leverages an efficient residual learning scheme to make it computationally feasible. A novel, direction-sensitive, and robust loss function is crucial to learning vector-field data. We present a detailed comparative study between the proposed super-resolution and the conventional cubic B-spline based vector-field super-resolution. Our method improves the peak-velocity to noise ratio of the flow field by 10 and 30% for in vivo cardiovascular and cerebrovascular data, respectively, for 4 × super-resolution over the state-of-the-art cubic B-spline. Significantly, our method offers 10x faster inference over the cubic B-spline. The proposed approach for super-resolution of 4D-flow data would potentially improve the subsequent calculation of hemodynamic quantities.",
      "url": "https://www.frontiersin.org/articles/10.3389/frai.2022.928181/full",
      "scholar_link": "/scholar?hl=en&cites=16189589645547975257",
      "citations": 22,
      "pdf_link": "",
      "categories": [
        "mri",
        "reconstruction",
        "ct"
      ],
      "primary_category": "mri",
      "thumbnail": "images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub028",
      "title": "clDice-a Novel Connectivity-Preserving Loss Function for Vessel Segmentation",
      "authors": "Johannes C Paetzold* and Suprosanna Shit* and Ivan Ezhov and Giles Tetteh and Ali Ertürk and Bjoern Menze",
      "year": 2019,
      "venue": "CVPR",
      "venue_tag": null,
      "doi": null,
      "abstract": "Accurate segmentation of vascular structures is an emerging research topic with relevance to clinical and biological research. The connectedness of the segmented vessels is often the most significant property for many applications such as disease modeling for neurodegeneration and stroke. We introduce a novel metric namely clDice, which is calculated on the intersection of centerlines and volumes as opposed to the traditional dice, which is calculated on volumes only. Firstly, we tested state-of-the-art vessel segmentation networks using the proposed metric as evaluation criteria and show that it captures vascular network properties superior to traditional metrics, such as the dice-coefficient. Secondly, we propose a differentiable form of clDice as a loss function for vessel segmentation. We find that training on clDice leads to segmentation with more accurate connectivity information, higher graph similarity and often superior volumetric scores.",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shit_clDice_-_A_Novel_Topology-Preserving_Loss_Function_for_Tubular_Structure_CVPR_2021_paper.pdf",
      "scholar_link": "/scholar?hl=en&cites=4005154896457950750,4831368935089680642",
      "citations": 20,
      "pdf_link": "",
      "categories": [
        "ct",
        "topology",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "images/publications/manual_added/clDice.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub030",
      "title": "Unsupervised anomaly localization with structural feature-autoencoders",
      "authors": "Felix Meissen and Johannes Paetzold and Georgios Kaissis and Daniel Rueckert",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Unsupervised Anomaly Detection has become a popular method to detect pathologies in medical images as it does not require supervision or labels for training. Most commonly, the anomaly detection model generates a “normal” version of an input image, and the pixel-wise -difference of the two is used to localize anomalies. However, large residuals often occur due to imperfect reconstruction of the complex anatomical structures present in most medical images. This method also fails to detect anomalies that are not characterized by large intensity differences to the surrounding tissue. We propose to tackle this problem using a feature-mapping function that transforms the input intensity images into a space with multiple channels where anomalies can be detected along different discriminative feature maps extracted from the original image. We then train an Autoencoder model in this space using structural …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-33842-7_2",
      "scholar_link": "/scholar?hl=en&cites=85876104182314169",
      "citations": 17,
      "pdf_link": "",
      "categories": [
        "detection",
        "ct",
        "generative",
        "reconstruction"
      ],
      "primary_category": "detection",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub031",
      "title": "FedCostWAvg: a new averaging for better federated learning",
      "authors": "Leon Mächler and Ivan Ezhov and Florian Kofler and Suprosanna Shit and Johannes C Paetzold and Timo Loehr and Claus Zimmer and Benedikt Wiestler and Bjoern H Menze",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We propose a simple new aggregation strategy for federated learning that won the MICCAI Federated Tumor Segmentation Challenge 2021 (FETS), the first ever challenge on Federated Learning in the Machine Learning community. Our method addresses the problem of how to aggregate multiple models that were trained on different data sets. Conceptually, we propose a new way to choose the weights when averaging the different models, thereby extending the current state of the art (FedAvg). Empirical validation demonstrates that our approach reaches a notable improvement in segmentation performance compared to FedAvg.",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-09002-8_34",
      "scholar_link": "/scholar?hl=en&cites=1167965136021175306",
      "citations": 17,
      "pdf_link": "",
      "categories": [
        "segmentation"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub032",
      "title": "A distance-based loss for smooth and continuous skin layer segmentation in optoacoustic images",
      "authors": "Stefan Gerl* and Johannes C Paetzold* and Hailong He* and Ivan Ezhov and Suprosanna Shit and Florian Kofler and Amirhossein Bayat and Giles Tetteh and Vasilis Ntziachristos and Bjoern Menze",
      "year": 2020,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Raster-scan optoacoustic mesoscopy (RSOM) is a powerful, non-invasive optical imaging technique for functional, anatomical, and molecular skin and tissue analysis. However, both the manual and the automated analysis of such images are challenging, because the RSOM images have very low contrast, poor signal to noise ratio, and systematic overlaps between the absorption spectra of melanin and hemoglobin. Nonetheless, the segmentation of the epidermis layer is a crucial step for many downstream medical and diagnostic tasks, such as vessel segmentation or monitoring of cancer progression. We propose a novel, shape-specific loss function that overcomes discontinuous segmentations and achieves smooth segmentation surfaces while preserving the same volumetric Dice and IoU. Further, we validate our epidermis segmentation through the sensitivity of vessel segmentation. We found a 20 …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-59725-2_30",
      "scholar_link": "/scholar?hl=en&cites=14841909004971981891",
      "citations": 16,
      "pdf_link": "",
      "categories": [
        "segmentation",
        "ct",
        "classification"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub033",
      "title": "A skeletonization algorithm for gradient-based optimization",
      "authors": "Martin J Menten and Johannes C Paetzold and Veronika A Zimmer and Suprosanna Shit and Ivan Ezhov and Robbie Holland and Monika Probst and Julia A Schnabel and Daniel Rueckert",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "The skeleton of a digital image is a compact representation of its topology, geometry, and scale. It has utility in many computer vision applications, such as image description, segmentation, and registration. However, skeletonization has only seen limited use in contemporary deep learning solutions. Most existing skeletonization algorithms are not differentiable, making it impossible to integrate them with gradient-based optimization. Compatible algorithms based on morphological operations and neural networks have been proposed, but their results often deviate from the geometry and topology of the true medial axis. This work introduces the first three-dimensional skeletonization algorithm that is both compatible with gradient-based optimization and preserves an object's topology. Our method is exclusively based on matrix additions and multiplications, convolutional operations, basic non-linear functions, and sampling from a uniform probability distribution, allowing it to be easily implemented in any major deep learning library. In benchmarking experiments, we prove the advantages of our skeletonization algorithm compared to non-differentiable, morphological, and neural-network-based baselines. Finally, we demonstrate the utility of our algorithm by integrating it with two medical image processing applications that use gradient-based optimization: deep-learning-based blood vessel segmentation, and multimodal registration of the mandible in computed tomography and magnetic resonance images.",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.html",
      "scholar_link": "/scholar?hl=en&cites=10424980767667442046",
      "citations": 14,
      "pdf_link": "",
      "categories": [
        "topology",
        "ct",
        "mri",
        "segmentation",
        "registration"
      ],
      "primary_category": "topology",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub034",
      "title": "Metgan: Generative tumour inpainting and modality synthesis in light sheet microscopy",
      "authors": "Izabela Horvath and Johannes Paetzold and Oliver Schoppe and Rami Al-Maskari and Ivan Ezhov and Suprosanna Shit and Hongwei Li and Ali Ertürk and Bjoern Menze",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Novel multimodal imaging methods are capable of generating extensive, super high resolution datasets for preclinical research. Yet, a massive lack of annotations prevents the broad use of deep learning to analyze such data. In this paper, we introduce a novel generative method which leverages real anatomical information to generate realistic image-label pairs of tumours. We construct a dual pathway generator, for the anatomical image and label, trained in a cycle-consistent setup, constrained by an independent, pretrained segmentor. Our method performs two concurrent tasks: domain adaptation and semantic synthesis, which, to our knowledge, has not been done before. The generated images yield significant quantitative improvement compared to existing methods that specialize in either of these tasks. To validate the quality of synthesis, we train segmentation networks on a dataset augmented with the synthetic data, substantially improving the segmentation over the baseline.",
      "url": "http://openaccess.thecvf.com/content/WACV2022/html/Horvath_METGAN_Generative_Tumour_Inpainting_and_Modality_Synthesis_in_Light_Sheet_WACV_2022_paper.html",
      "scholar_link": "/scholar?hl=en&cites=18351057609625304179,14134298536940258229",
      "citations": 13,
      "pdf_link": "",
      "categories": [
        "generative",
        "microscopy",
        "ct",
        "segmentation"
      ],
      "primary_category": "generative",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub035",
      "title": "Transfer learning from synthetic data reduces need for labels to segment brain vasculature and neural pathways in 3D",
      "authors": "Johannes C Paetzold* and Oliver Schoppe* and Rami Al-Maskari and Giles Tetteh and Velizar Efremov and Mihail I Todorov and Ruiyao Cai and Hongcheng Mai and Zhouyi Rong and Ali Ertuerk and Bjoern H Menze",
      "year": 2019,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Novel microscopic techniques yield high-resolution volumetric scans of complex anatomical structures such as the blood vasculature or the nervous system. Here, we show how transfer learning and synthetic data generation can be used to train deep neural networks to segment these structures successfully in the absence of or with very limited training data.",
      "url": "https://openreview.net/forum?id=BJe02gRiY4",
      "scholar_link": "/scholar?hl=en&cites=2193675142490892307",
      "citations": 12,
      "pdf_link": "",
      "categories": [
        "ct",
        "microscopy"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub036",
      "title": "A deep learning approach to predict collateral flow in stroke patients using radiomic features from perfusion images",
      "authors": "Giles Tetteh and Fernando Navarro and Raphael Meier and Johannes Kaesmacher and Johannes C Paetzold and Jan S Kirschke and Claus Zimmer and Roland Wiest and Bjoern H Menze",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Collateral circulation results from specialized anastomotic channels which are capable of providing oxygenated blood to regions with compromised blood flow caused by arterial obstruction. The quality of collateral circulation has been established as a key factor in determining the likelihood of a favorable clinical outcome and goes a long way to determining the choice of a stroke care model. Though many imaging and grading methods exist for quantifying collateral blood flow, the actual grading is mostly done through manual inspection. This approach is associated with a number of challenges. First, it is time-consuming. Second, there is a high tendency for bias and inconsistency in the final grade assigned to a patient depending on the experience level of the clinician. We present a multi-stage deep learning approach to predict collateral flow grading in stroke patients based on radiomic features extracted from MR perfusion data. First, we formulate a region of interest detection task as a reinforcement learning problem and train a deep learning network to automatically detect the occluded region within the 3D MR perfusion volumes. Second, we extract radiomic features from the obtained region of interest through local image descriptors and denoising auto-encoders. Finally, we apply a convolutional neural network and other machine learning classifiers to the extracted radiomic features to automatically predict the collateral flow grading of the given patient volume as one of three severity classes - no flow (0), moderate flow (1), and good flow (2). Results from our experiments show an overall accuracy of 72% in the three-class prediction task. With …",
      "url": "https://www.frontiersin.org/journals/neurology/articles/10.3389/fneur.2023.1039693/full",
      "scholar_link": "/scholar?hl=en&cites=14373925493626964766",
      "citations": 10,
      "pdf_link": "",
      "categories": [
        "ct",
        "reconstruction",
        "detection"
      ],
      "primary_category": "ct",
      "thumbnail": "images/publications/thumbnails/a_deep_learning_approach_to_pr.jpg",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub037",
      "title": "Link prediction for flow-driven spatial networks",
      "authors": "Bastian Wittmann and Johannes C Paetzold and Chinmay Prabhakar and Daniel Rueckert and Bjoern Menze",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Link prediction algorithms aim to infer the existence of connections (or links) between nodes in network-structured data and are typically applied to refine the connectivity among nodes. In this work, we focus on link prediction for flow-driven spatial networks, which are embedded in a Euclidean space and relate to physical exchange and transportation processes (eg, blood flow in vessels or traffic flow in road networks). To this end, we propose the Graph Attentive Vectors (GAV) link prediction framework. GAV models simplified dynamics of physical flow in spatial networks via an attentive, neighborhood-aware message-passing paradigm, updating vector embeddings in a constrained manner. We evaluate GAV on eight flow-driven spatial networks given by whole-brain vessel graphs and road networks. GAV demonstrates superior performances across all datasets and metrics and outperformed the state-of-the-art on the ogbl-vessel benchmark at the time of submission by 12%(98.38 vs. 87.98 AUC). All code is publicly available on GitHub.",
      "url": "https://openaccess.thecvf.com/content/WACV2024/html/Wittmann_Link_Prediction_for_Flow-Driven_Spatial_Networks_WACV_2024_paper.html",
      "scholar_link": "/scholar?hl=en&cites=8516225310587467902",
      "citations": 9,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub038",
      "title": "Robust, primitive, and unsupervised quality estimation for segmentation ensembles",
      "authors": "Florian Kofler and Ivan Ezhov and Lucas Fidon and Carolin M Pirkl and Johannes C Paetzold and Egon Burian and Sarthak Pati and Malek El Husseini and Fernando Navarro and Suprosanna Shit and Jan Kirschke and Spyridon Bakas and Claus Zimmer and Benedikt Wiestler and Bjoern H Menze",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "A multitude of image-based machine learning segmentation and classification algorithms has recently been proposed, offering diagnostic decision support for the identification and characterization of glioma, Covid-19 and many other diseases. Even though these algorithms often outperform human experts in segmentation tasks, their limited reliability, and in particular the inability to detect failure cases, has hindered translation into clinical practice. To address this major shortcoming, we propose an unsupervised quality estimation method for segmentation ensembles. Our primitive solution examines discord in binary segmentation maps to automatically flag segmentation results that are particularly error-prone and therefore require special assessment by human readers. We validate our method both on segmentation of brain glioma in multi-modal magnetic resonance - and of lung lesions in computer tomography images. Additionally, our method provides an adaptive prioritization mechanism to maximize efficacy in use of human expert time by enabling radiologists to focus on the most difficult, yet important cases while maintaining full diagnostic autonomy. Our method offers an intuitive and reliable uncertainty estimation from segmentation ensembles and thereby closes an important gap toward successful translation of automatic segmentation into clinical routine.",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2021.752780/full",
      "scholar_link": "/scholar?hl=en&cites=16768164530965923588",
      "citations": 9,
      "pdf_link": "",
      "categories": [
        "classification",
        "segmentation",
        "mri",
        "ct"
      ],
      "primary_category": "classification",
      "thumbnail": "images/publications/thumbnails/robust__primitive__and_unsuper.jpg",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub039",
      "title": "Generalized wasserstein dice loss, test-time augmentation, and transformers for the BraTS 2021 challenge",
      "authors": "Lucas Fidon and Suprosanna Shit and Ivan Ezhov and Johannes C Paetzold and Sébastien Ourselin and Tom Vercauteren",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Brain tumor segmentation from multiple Magnetic Resonance Imaging (MRI) modalities is a challenging task in medical image computation. The main challenges lie in the generalizability to a variety of scanners and imaging protocols. In this paper, we explore strategies to increase model robustness without increasing inference time. Towards this aim, we explore finding a robust ensemble from models trained using different losses, optimizers, and train-validation data split. Importantly, we explore the inclusion of a transformer in the bottleneck of the U-Net architecture. While we find transformer in the bottleneck performs slightly worse than the baseline U-Net in average, the generalized Wasserstein Dice loss consistently produces superior results. Further, we adopt an efficient test time augmentation strategy for faster and robust inference. Our final ensemble of seven 3D U-Nets with test-time augmentation produces …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-09002-8_17",
      "scholar_link": "/scholar?hl=en&cites=15649403381621132226",
      "citations": 9,
      "pdf_link": "",
      "categories": [
        "mri",
        "ct",
        "segmentation"
      ],
      "primary_category": "mri",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub040",
      "title": "A Baseline for Predicting Glioblastoma Patient Survival Time with Classical Statistical Models and Primitive Features Ignoring Image Information",
      "authors": "Florian Kofler and Johannes C Paetzold and Ivan Ezhov and Suprosanna Shit and Daniel Krahulec and Jan S Kirschke and Claus Zimmer and Benedikt Wiestler and Bjoern H Menze",
      "year": 2020,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Gliomas are the most prevalent primary malignant brain tumors in adults. Until now an accurate and reliable method to predict patient survival time based on medical imaging and meta-information has not been developed [3]. Therefore, the survival time prediction task was introduced to the Multimodal Brain Tumor Segmentation Challenge (BraTS) to facilitate research in survival time prediction.Here we present our submissions to the BraTS survival challenge based on classical statistical models to which we feed the provided metadata as features. We intentionally ignore the available image information to explore how patient survival can be predicted purely by metadata. We achieve our best accuracy on the validation set using a simple median regression model taking only patient age into account. We suggest using our model as a baseline to benchmark the added predictive value of sophisticated features for …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-46640-4_24",
      "scholar_link": "/scholar?hl=en&cites=112435818079113752",
      "citations": 8,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation",
        "mri",
        "histology",
        "generative"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub041",
      "title": "Machine learning analysis of human skin by optoacoustic mesoscopy for automated extraction of psoriasis and aging biomarkers",
      "authors": "Hailong He* and Johannes C Paetzold* and Nils Börner and Erik Riedel and Stefan Gerl and Simon Schneider and Chiara Fisher and Ivan Ezhov and Suprosanna Shit and Hongwei Li and Daniel Rückert and Juan Aguirre and Tilo Biedermann and Ulf Darsow and Bjoern Menze and Vasilis Ntziachristos",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Ultra-wideband raster-scan optoacoustic mesoscopy (RSOM) is a novel modality that has demonstrated unprecedented ability to visualize epidermal and dermal structures in-vivo. However, an automatic and quantitative analysis of three-dimensional RSOM datasets remains unexplored. In this work we present our framework: Deep Learning RSOM Analysis Pipeline (DeepRAP), to analyze and quantify morphological skin features recorded by RSOM and extract imaging biomarkers for disease characterization. DeepRAP uses a multi-network segmentation strategy based on convolutional neural networks with transfer learning. This strategy enabled the automatic recognition of skin layers and subsequent segmentation of dermal microvasculature with an accuracy equivalent to human assessment. DeepRAP was validated against manual segmentation on 25 psoriasis patients under treatment and our biomarker …",
      "url": "https://ieeexplore.ieee.org/abstract/document/10409213/",
      "scholar_link": "/scholar?hl=en&cites=3581592034499907356",
      "citations": 7,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub042",
      "title": "Velocity-to-pressure (V2P)-net: inferring relative pressures from time-varying 3D fluid flow velocities",
      "authors": "Suprosanna Shit and Dhritiman Das and Ivan Ezhov and Johannes C Paetzold and Augusto F Sanches and Nils Thuerey and Bjoern H Menze",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Pressure inference from a series of velocity fields is a common problem arising in medical imaging when analyzing 4D data. Traditional approaches primarily rely on a numerical scheme to solve the pressure-Poisson equation to obtain a dense pressure inference. This involves heavy expert intervention at each stage and requires significant computational resources. Concurrently, the application of current machine learning algorithms for solving partial differential equations is limited to domains with simple boundary conditions. We address these challenges in this paper and present V2P-Net: a novel, neural-network-based approach as an alternative method for inferring pressure from the observed velocity fields. We design an end-to-end hybrid-network architecture motivated by the conventional Navier-Stokes solver, which encapsulates the complex boundary conditions. It achieves accurate pressure …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-78191-0_42",
      "scholar_link": "/scholar?hl=en&cites=13350201158550030941",
      "citations": 7,
      "pdf_link": "",
      "categories": [
        "ct",
        "pet",
        "generative",
        "segmentation",
        "registration"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub043",
      "title": "FedPIDAvg: A PID controller inspired aggregation method for federated learning",
      "authors": "Leon Mächler and Ivan Ezhov and Suprosanna Shit and Johannes C Paetzold",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "This paper presents FedPIDAvg, the winning submission to the Federated Tumor Segmentation Challenge 2022 (FETS22). Inspired by FedCostWAvg, our winning contribution to FETS21, we contribute an improved aggregation strategy for federated and collaborative learning. FedCostWAvg is a weighted averaging method that not only considers the number of training samples of each cluster but also the size of the drop of the respective cost function in the last federated round. This can be interpreted as the derivative part of a PID controller (proportional-integral-derivative controller). In FedPIDAvg, we further add the missing integral term. Another key challenge was the vastly varying size of data samples per center. We addressed this by modeling the data center sizes as following a Poisson distribution and choosing the training iterations per center accordingly. Our method outperformed all other submissions.",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-44153-0_20",
      "scholar_link": "/scholar?hl=en&cites=12394746102201168524",
      "citations": 6,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub045",
      "title": "Retinal vasculature of different diameters and plexuses exhibit distinct vulnerability in varying severity of diabetic retinopathy",
      "authors": "Alaa E Fayed and Martin J Menten and Linus Kreitner and Johannes C Paetzold and Daniel Rueckert and Sherry M Bassily and Ramy R Fikry and Ahmed M Hagag and Sobha Sivaprasad",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "To study the changes in vessel densities (VD) stratified by vessel diameter in the retinal superficial and deep vascular complexes (SVC/DVC) using optical coherence tomography angiography (OCTA) images obtained from people with diabetes and age-matched healthy controls.We quantified the VD based on vessel diameter categorized as <10, 10–20 and >20 μm in the SVC/DVC obtained on 3 × 3 mm2 OCTA scans using a deep learning-based segmentation and vascular graph extraction tool in people with diabetes and age-matched healthy controls.OCTA images obtained from 854 eyes of 854 subjects were divided into 5 groups: healthy controls (n = 555); people with diabetes with no diabetic retinopathy (DR, n = 90), mild and moderate non-proliferative DR (NPDR) (n = 96), severe NPDR (n = 42) and proliferative DR (PDR) (n = 71). Both SVC and DVC showed …",
      "url": "https://www.nature.com/articles/s41433-024-03021-4",
      "scholar_link": "/scholar?hl=en&cites=16044066264792667412",
      "citations": 5,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub046",
      "title": "Differentially Private Guarantees for Analytics and Machine Learning on Graphs: A Survey of Results",
      "authors": "Tamara T Mueller and Dmitrii Usynin and Johannes C Paetzold and Rickmer Braren and Daniel Rueckert and Georgios Kaissis",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We study the applications of differential privacy (DP) in the context of graph-structured data and discuss the formulations of DP applicable to the publication of graphs and their associated statistics as well as machine learning on graph-based data, including graph neural networks (GNNs). Interpreting DP guarantees in the context of graph-structured data can be challenging, as individual data points are interconnected (often non-linearly or sparsely). This connectivity complicates the computation of individual privacy loss in differentially private learning. The problem is exacerbated by an absence of a single, well-established formulation of DP in graph settings. This issue extends to the domain of GNNs, rendering private machine learning on graph-structured data a challenging task. A lack of prior systematisation work motivated us to study graph-based learning from a privacy perspective. In this work, we systematise different formulations of DP on graphs, discuss challenges and promising applications, including the GNN domain. We compare and separate works into graph analytics tasks and graph learning tasks with GNNs. We conclude our work with a discussion of open questions and potential directions for further research in this area.",
      "url": "https://journalprivacyconfidentiality.org/index.php/jpc/article/view/820",
      "scholar_link": "/scholar?hl=en&cites=18063963141161228159",
      "citations": 5,
      "pdf_link": "",
      "categories": [
        "gnn",
        "ct"
      ],
      "primary_category": "gnn",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub048",
      "title": "Segmentation of peripancreatic arteries in multispectral computed tomography imaging",
      "authors": "Alina Dima and Johannes C Paetzold and Friederike Jungmann and Tristan Lemke and Philipp Raffler and Georgios Kaissis and Daniel Rueckert and Rickmer Braren",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Pancreatic ductal adenocarcinoma is an aggressive form of cancer with a poor prognosis, where the operability and hence chance of survival is strongly affected by the tumor infiltration of the arteries. In an effort to enable an automated analysis of the relationship between the local arteries and the tumor, we propose a method for segmenting the peripancreatic arteries in multispectral CT images in the arterial phase. A clinical dataset was collected, and we designed a fast semi-manual annotation procedure, which requires around 20 min of annotation time per case. Next, we trained a U-Net based model to perform binary segmentation of the peripancreatic arteries, where we obtained a near perfect segmentation with a Dice score of  in our best performing model. Furthermore, we designed a clinical evaluation procedure for our models; performed by two radiologists, yielding a complete segmentation of …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-87589-3_61",
      "scholar_link": "/scholar?hl=en&cites=3957992103223418905",
      "citations": 5,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub051",
      "title": "Self-pruning graph neural network for predicting inflammatory disease activity in multiple sclerosis from brain MR images",
      "authors": "Chinmay Prabhakar and Hongwei Bran Li and Johannes C Paetzold and Timo Loehr and Chen Niu and Mark Mühlau and Daniel Rueckert and Benedikt Wiestler and Bjoern Menze",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Multiple Sclerosis (MS) is a severe neurological disease characterized by inflammatory lesions in the central nervous system. Hence, predicting inflammatory disease activity is crucial for disease assessment and treatment. However, MS lesions can occur throughout the brain and vary in shape, size and total count among patients. The high variance in lesion load and locations makes it challenging for machine learning methods to learn a globally effective representation of whole-brain MRI scans to assess and predict disease. Technically it is non-trivial to incorporate essential biomarkers such as lesion load or spatial proximity. Our work represents the first attempt to utilize graph neural networks (GNN) to aggregate these biomarkers for a novel global representation. We propose a two-stage MS inflammatory disease activity prediction approach. First, a 3D segmentation network detects lesions, and a self …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-43993-3_22",
      "scholar_link": "/scholar?hl=en&cites=8492780280962319883",
      "citations": 4,
      "pdf_link": "",
      "categories": [
        "gnn",
        "ct",
        "mri",
        "segmentation"
      ],
      "primary_category": "gnn",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub052",
      "title": "Synthetic data facilitates deep-learning-based segmentation of OCT angiography images without human annotations",
      "authors": "Martin Joseph Menten and Linus Kreitner and Johannes CC Paetzold and Ahmed M Hagag and Sherry M Bassily and Sobha Sivaprasad and Daniel Rueckert and Alaa E Fayed",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Purpose: Quantitative analysis of optical coherence tomography angiography (OCTA) images often requires segmentation of the blood vessels. So far, the application of deep learning to this task has been inhibited by a lack of training data with expert-derived labels. We propose a strategy that circumvents the need for human annotations by generating synthetic OCTA images and using these to train a segmentation neural network.Methods: Synthetic OCTA images are created in two steps (see figure 1). Initially, the retinal vasculature is modeled using a statistical simulation. Blood vessels are iteratively grown until they supply the entire simulation volume with oxygen. Vessel growth is governed by a set of rules that enforces realistic physiological properties, such as vessel radius, density, bifurcation frequency, and branching ratio. The obtained vasculature models are converted to grayscale images. The images' contrast and noise are adapted to resemble that of real OCTA images using a generative adversarial network with cycle-consistency loss.",
      "url": "https://iovs.arvojournals.org/article.aspx?articleid=2790199",
      "scholar_link": "/scholar?hl=en&cites=17229899923876745428",
      "citations": 4,
      "pdf_link": "",
      "categories": [
        "generative",
        "ct",
        "segmentation"
      ],
      "primary_category": "generative",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub053",
      "title": "Geometric deep learning for disease classification in octa images",
      "authors": "Johannes CC Paetzold and Laurin Lux and Linus Kreitner and Ivan Ezhov and Suprosanna Shit and Andrew J Lotery and Martin Joseph Menten and Daniel Rueckert",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Purpose: The retina's vasculature intrinsically forms a physical graph structure. Advanced concepts from geometric deep learning, such as graph convolutional networks (GCN), can solve complex machine learning tasks on any graph. As such, geometric deep learning, specifically graph learning lends itself excellently to advancing the automated analysis of the retinal vessels and associated diseases. In this study, we demonstrate the feasibility of vascular graph representations to ophthalmology by using a GCN to diagnose diabetic retinopathy (DR) from OCTA images.Methods: Our method consists of three steps. First, we apply a U-Net, trained on synthetic OCTA images (Menten et al., 2021), to segment the vessels. Second, we extract the vascular graph, where vessel bifurcations are the nodes, and the connecting vessels are the edges using the Voreen framework. Third, we apply a GCN to classify the vascular …",
      "url": "https://iovs.arvojournals.org/article.aspx?articleid=2790851",
      "scholar_link": "/scholar?hl=en&cites=6908441915959576504",
      "citations": 4,
      "pdf_link": "",
      "categories": [
        "classification",
        "gnn",
        "ct"
      ],
      "primary_category": "classification",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub054",
      "title": "Suprosanna Shit, Richard McKinley, Spyridon Bakas, et al. Are we using appropriate segmentation metrics? Identifying correlates of human expert perception for CNN training beyond rolling the DICE coefficient",
      "authors": "Florian Kofler and Ivan Ezhov and Fabian Isensee and Christoph Berger and Maximilian Korner and Johannes Paetzold and Hongwei Li",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "",
      "url": "https://scholar.google.com/scholar?cluster=5624596369850357938&hl=en&oi=scholarr",
      "scholar_link": "/scholar?hl=en&cites=5624596369850357938",
      "citations": 4,
      "pdf_link": "",
      "categories": [
        "segmentation"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub055",
      "title": "Topograph: An efficient Graph-Based Framework for Strictly Topology Preserving Image Segmentation",
      "authors": "Laurin Lux and Alexander H Berger and Alexander Weers and Nico Stucki and Daniel Rueckert and Ulrich Bauer and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Topological correctness plays a critical role in many image segmentation tasks, yet most networks are trained using pixel-wise loss functions, such as Dice, neglecting topological accuracy. Existing topology-aware methods often lack robust topological guarantees, are limited to specific use cases, or impose high computational costs. In this work, we propose a novel, graph-based framework for topologically accurate image segmentation that is both computationally efficient and generally applicable. Our method constructs a component graph that fully encodes the topological information of both the prediction and ground truth, allowing us to efficiently identify topologically critical regions and aggregate a loss based on local neighborhood information. Furthermore, we introduce a strict topological metric capturing the homotopy equivalence between the union and intersection of prediction-label pairs. We formally prove the topological guarantees of our approach and empirically validate its effectiveness on binary and multi-class datasets. Our loss demonstrates state-of-the-art performance with up to fivefold faster loss computation compared to persistent homology methods.",
      "url": "https://openreview.net/forum?id=Q0zmmNNePz",
      "scholar_link": "/scholar?hl=en&cites=6484828534471745661",
      "citations": 3,
      "pdf_link": "",
      "categories": [
        "topology",
        "ct",
        "segmentation"
      ],
      "primary_category": "topology",
      "thumbnail": "images/publications/manual_added/topograph.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub056",
      "title": "Generating synthetic high-resolution spinal STIR and T1w images from T2w FSE and low-resolution axial Dixon",
      "authors": "Robert Graf and Paul-Sören Platzek and Evamaria Olga Riedel and Su Hwan Kim and Nicolas Lenhart and Constanze Ramschütz and Karolin Johanna Paprottka and Olivia Ruriko Kertels and Hendrik Kristian Möller and Matan Atad and Robin Bülow and Nicole Werner and Henry Völzke and Carsten Oliver Schmidt and Benedikt Wiestler and Johannes C Paetzold and Daniel Rueckert and Jan Stefan Kirschke",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "To generate sagittal T1-weighted fast spin echo (T1w FSE) and short tau inversion recovery (STIR) images from sagittal T2-weighted (T2w) FSE and axial T1w gradient echo Dixon technique (T1w-Dixon) sequences.This retrospective study used three existing datasets: “Study of Health in Pomerania” (SHIP, 3142 subjects, 1.5 Tesla), “German National Cohort” (NAKO, 2000 subjects, 3 Tesla), and an internal dataset (157 patients 1.5/3 Tesla). We generated synthetic sagittal T1w FSE and STIR images from sagittal T2w FSE and low-resolution axial T1w-Dixon sequences based on two successively applied 3D Pix2Pix deep learning models. “Peak signal-to-noise ratio” (PSNR) and “structural similarity index metric” (SSIM) were used to evaluate the generated image quality on an ablations test. A Turing test, where seven radiologists rated 240 images as either natively acquired or …",
      "url": "https://link.springer.com/article/10.1007/s00330-024-11047-1",
      "scholar_link": "/scholar?hl=en&cites=18370876008374258760",
      "citations": 3,
      "pdf_link": "",
      "categories": [
        "mri",
        "ct"
      ],
      "primary_category": "mri",
      "thumbnail": "images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub057",
      "title": "Totalvibesegmentator: Full torso segmentation for the Nako and UK biobank in volumetric interpolated breath-hold examination body images",
      "authors": "Robert Graf and Paul-Sören Platzek and Evamaria Olga Riedel and Constanze Ramschütz and Sophie Starck and Hendrik Kristian Möller and Matan Atad and Henry Völzke and Robin Bülow and Carsten Oliver Schmidt and Julia Rüdebusch and Matthias Jung and Marco Reisert and Jakob Weiss and Maximilian Löffler and Fabian Bamberg and Bene Wiestler and Johannes C Paetzold and Daniel Rueckert and Jan Stefan Kirschke",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Objectives To present a publicly available torso segmentation network for large epidemiology datasets on volumetric interpolated breath-hold examination (VIBE) images. Materials & Methods We extracted preliminary segmentations from TotalSegmentator, spine, and body composition networks for VIBE images, then improved them iteratively and retrained a nnUNet network. Using subsets of NAKO (85 subjects) and UK Biobank (16 subjects), we evaluated with Dice-score on a holdout set (12 subjects) and existing organ segmentation approach (1000 subjects), generating 71 semantic segmentation types for VIBE images. We provide an additional network for the vertebra segments 22 individual vertebra types. Results We achieved an average Dice score of 0.89+-0.07 overall 71 segmentation labels. We scored> 0.90 Dice-score on the abdominal organs except for the pancreas with a Dice of 0.70. Conclusion Our …",
      "url": "https://ui.adsabs.harvard.edu/abs/2024arXiv240600125G/abstract",
      "scholar_link": "/scholar?hl=en&cites=16772366218536540708",
      "citations": 3,
      "pdf_link": "",
      "categories": [
        "segmentation",
        "generative",
        "ct"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub058",
      "title": "Automated analysis of diabetic retinopathy using vessel segmentation maps as inductive bias",
      "authors": "Linus Kreitner and Ivan Ezhov and Daniel Rueckert and Johannes C Paetzold and Martin J Menten",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Recent studies suggest that early stages of diabetic retinopathy (DR) can be diagnosed by monitoring vascular changes in the deep vascular complex. In this work, we investigate a novel method for automated DR grading based on ultra-wide optical coherence tomography angiography (UW-OCTA) images. Our work combines OCTA scans with their vessel segmentations, which then serve as inputs to task specific networks for lesion segmentation, image quality assessment and DR grading. For this, we generate synthetic OCTA images to train a segmentation network that can be directly applied on real OCTA data. We test our approach on MICCAI 2022’s DR analysis challenge (DRAC). In our experiments, the proposed method performs equally well as the baseline model.",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-33658-4_2",
      "scholar_link": "/scholar?hl=en&cites=16381223451608842331",
      "citations": 3,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub059",
      "title": "Graflow: Neural blood flow solver for vascular graph",
      "authors": "Suprosanna Shit and Chinmay Prabhakar and Johannes C Paetzold and Martin J Menten and Bastian Wittmann and Ivan Ezhov",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Simulating blood flow is paramount in identifying flow-based biomarkers for vascular-related diseases. A segmented vessel graph is used as a domain for the simulation. Traditionally, partial differential equations are solved with numerical methods. Here, we propose an alternative solver for the simulation of blood flow on a vascular graph leveraging geometric deep learning. Specifically, we reformulate the problem as an implicit function on the graph and learn the simulation by imposing the physics in the loss through a message passing layer. The resultant flow is accurate, fast, and applicable to various tasks.",
      "url": "https://openreview.net/forum?id=8W1ar7zATN",
      "scholar_link": "/scholar?hl=en&cites=1768981827562805642",
      "citations": 3,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub060",
      "title": "A deep learning approach to predicting collateral flow in stroke patients using radiomic features from perfusion images",
      "authors": "Giles Tetteh and Fernando Navarro and Johannes Paetzold and Jan Kirschke and Claus Zimmer and Bjoern H Menze",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Collateral circulation results from specialized anastomotic channels which are capable of providing oxygenated blood to regions with compromised blood flow caused by ischemic injuries. The quality of collateral circulation has been established as a key factor in determining the likelihood of a favorable clinical outcome and goes a long way to determine the choice of stroke care model - that is the decision to transport or treat eligible patients immediately. Though there exist several imaging methods and grading criteria for quantifying collateral blood flow, the actual grading is mostly done through manual inspection of the acquired images. This approach is associated with a number of challenges. First, it is time-consuming - the clinician needs to scan through several slices of images to ascertain the region of interest before deciding on what severity grade to assign to a patient. Second, there is a high tendency for bias and inconsistency in the final grade assigned to a patient depending on the experience level of the clinician. We present a deep learning approach to predicting collateral flow grading in stroke patients based on radiomic features extracted from MR perfusion data. First, we formulate a region of interest detection task as a reinforcement learning problem and train a deep learning network to automatically detect the occluded region within the 3D MR perfusion volumes. Second, we extract radiomic features from the obtained region of interest through local image descriptors and denoising auto-encoders. Finally, we apply a convolutional neural network and other machine learning classifiers to the extracted radiomic features to …",
      "url": "https://arxiv.org/abs/2110.12508",
      "scholar_link": "/scholar?hl=en&cites=11005045086392742690",
      "citations": 3,
      "pdf_link": "",
      "categories": [
        "ct",
        "reconstruction",
        "detection"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub061",
      "title": "A-Net: Automatic Detection and Segmentation of Aneurysm",
      "authors": "Suprosanna Shit and Ivan Ezhov and Johannes C Paetzold and Bjoern Menze",
      "year": 2020,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We propose an automatic solution for the CADA 2020 challenge to detect aneurysm from Digital Subtraction Angiography (DSA) images. Our method relies on 3D U-net as the backbone and heavy data augmentation with a carefully chosen loss function. We were able to generalize well using our solution (despite training on a small dataset) that is demonstrated through accurate detection and segmentation on the test data. ",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-72862-5_5",
      "scholar_link": "/scholar?hl=en&cites=18436728764798006417",
      "citations": 3,
      "pdf_link": "",
      "categories": [
        "segmentation",
        "ct",
        "detection",
        "mri",
        "x-ray",
        "generative",
        "classification"
      ],
      "primary_category": "segmentation",
      "thumbnail": "images/publications/thumbnails/a_net__automatic_detection_and.jpg",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub062",
      "title": "Topologically faithful multi-class segmentation in medical images",
      "authors": "Alexander H Berger and Laurin Lux and Nico Stucki and Vincent Bürgin and Suprosanna Shit and Anna Banaszak and Daniel Rueckert and Ulrich Bauer and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": "MICCAI",
      "doi": null,
      "abstract": "Topological accuracy in medical image segmentation is a highly important property for downstream applications such as network analysis and flow modeling in vessels or cell counting. Recently, significant methodological advancements have brought well-founded concepts from algebraic topology to binary segmentation. However, these approaches have been underexplored in multi-class segmentation scenarios, where topological errors are common. We propose a general loss function for topologically faithful multi-class segmentation extending the recent Betti matching concept, which is based on induced matchings of persistence barcodes. We project the N-class segmentation problem to N single-class segmentation tasks, which allows us to use 1-parameter persistent homology, making training of neural networks computationally feasible. We validate our method on a comprehensive set of four medical …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-72111-3_68",
      "scholar_link": "/scholar?hl=en&cites=15618692918927015539",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "topology",
        "segmentation",
        "ct"
      ],
      "primary_category": "topology",
      "thumbnail": "images/publications/manual_added/Betti.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub063",
      "title": "Simulation-based segmentation of blood vessels in cerebral 3D OCTA images",
      "authors": "Bastian Wittmann and Lukas Glandorf and Johannes C Paetzold and Tamaz Amiranashvili and Thomas Wälchli and Daniel Razansky and Bjoern Menze",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Segmentation of blood vessels in murine cerebral 3D OCTA images is foundational for in vivo quantitative analysis of the effects of neurovascular disorders, such as stroke or Alzheimer’s, on the vascular network. However, to accurately segment blood vessels with state-of-the-art deep learning methods, a vast amount of voxel-level annotations is required. Since cerebral 3D OCTA images are typically plagued by artifacts and generally have a low signal-to-noise ratio, acquiring manual annotations poses an especially cumbersome and time-consuming task. To alleviate the need for manual annotations, we propose utilizing synthetic data to supervise segmentation algorithms. To this end, we extract patches from vessel graphs and transform them into synthetic cerebral 3D OCTA images paired with their matching ground truth labels by simulating the most dominant 3D OCTA artifacts. In extensive experiments, we …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-72111-3_61",
      "scholar_link": "/scholar?hl=en&cites=5333932130420529279",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub064",
      "title": "3D Vessel Graph Generation Using Denoising Diffusion",
      "authors": "Chinmay Prabhakar and Suprosanna Shit and Fabio Musio and Kaiyuan Yang and Tamaz Amiranashvili and Johannes C Paetzold and Hongwei Bran Li and Bjoern Menze",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Blood vessel networks, represented as 3D graphs, help predict disease biomarkers, simulate blood flow, and aid in synthetic image generation, relevant in both clinical and pre-clinical settings. However, generating realistic vessel graphs that correspond to an anatomy of interest is challenging. Previous methods aimed at generating vessel trees mostly in an autoregressive style and could not be applied to vessel graphs with cycles such as capillaries or specific anatomical structures such as the Circle of Willis. Addressing this gap, we introduce the first application of denoising diffusion models in 3D vessel graph generation. Our contributions include a novel, two-stage generation method that sequentially denoises node coordinates and edges. We experiment with two real-world vessel datasets, consisting of microscopic capillaries and major cerebral vessels, and demonstrate the generalizability of our method for …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-72120-5_1",
      "scholar_link": "/scholar?hl=en&cites=7887278537190073887",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "generative",
        "reconstruction",
        "ct",
        "microscopy"
      ],
      "primary_category": "generative",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub065",
      "title": "Vesselformer: Towards complete 3d vessel graph generation from images",
      "authors": "Chinmay Prabhakar and Suprosanna Shit and Johannes C Paetzold and Ivan Ezhov and Rajat Koner and Hongwei Li and Florian Sebastian Kofler and Bjoern Menze",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "The reconstruction of graph representations from Images (Image-to-graph) is a frequent task, especially vessel graph extraction from biomedical images. Traditionally, this problem is tackled by a two-stage process: segmentation followed by skeletonization. However, the ambiguity in the heuristic-based pruning of the centerline graph from the skeleta makes it hard to achieve a compact yet faithful graph representation. Recently,\\textit {Relationformer} proposed an end-to-end solution to extract graphs directly from images. However, it does not consider edge features, particularly radius information, which is crucial in many applications such as flow simulation. Further, Relationformer predicts only patch-based graphs. In this work, we address these two shortcomings. We propose a task-specific token, namely radius-token, which explicitly focuses on capturing radius information between two nodes. Second, we propose an efficient algorithm to infer a large 3D graph from patch inference. Finally, we show experimental results on a synthetic vessel dataset and achieve the first 3D complete graph prediction. Code is available at\\url {https://github. com/****}.",
      "url": "https://proceedings.mlr.press/v227/prabhakar24a.html",
      "scholar_link": "/scholar?hl=en&cites=1692895369671101166",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "ct",
        "topology",
        "segmentation",
        "reconstruction"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub069",
      "title": "Structured knowledge graphs for classifying unseen patterns in radiographs",
      "authors": "Chinmay Prabhakar and Anjany Sekuboyina and Hongwei Bran Li and Johannes C Paetzold and Suprosanna Shit and Tamaz Amiranashvili and Jens Kleesiek and Bjoern Menze",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "The presence of annotated datasets is crucial to the performance of modern machine learning algorithms. However, obtaining richly annotated datasets is not always possible, especially for novel or rare diseases. This becomes especially challenging in the realm of multi-label classification of chest radiographs, due to the presence of numerous unknown disease types and the limited information inherent to x-ray images. Ideally, we would like to develop models that can reliably label such unseen patterns (classes). In this work, we present a knowledge graph-based approach to predict such novel, unseen classes. Our method directly injects the semantic relationships between seen and unseen disease classes. Specifically, we propose a principled approach to parsing and processing a knowledge graph conditioned on the given task. We show that our method matches the labeling performance of the state-of-the-art while outperforming it on unseen classes by a substantial\\textbf {2}% gain on chest X-ray classification. Crucially, we demonstrate that embedding disease-specific knowledge as a graph provides inherent explainability.(The code is available at\\url {https://github. com/chinmay5/ml-cxr-gzsl-kg})",
      "url": "https://proceedings.mlr.press/v194/prabhakar22a",
      "scholar_link": "/scholar?hl=en&cites=6258091338753480591",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "x-ray",
        "ct",
        "classification"
      ],
      "primary_category": "x-ray",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub070",
      "title": "Can collaborative learning be private, robust and scalable?",
      "authors": "Dmitrii Usynin and Helena Klause and Johannes C Paetzold and Daniel Rueckert and Georgios Kaissis",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "In federated learning for medical image analysis, the safety of the learning protocol is paramount. Such settings can often be compromised by adversaries that target either the private data used by the federation or the integrity of the model itself. This requires the medical imaging community to develop mechanisms to train collaborative models that are private and robust against adversarial data. In response to these challenges, we propose a practical open-source framework to study the effectiveness of combining differential privacy, model compression and adversarial training to improve the robustness of models against adversarial samples under train- and inference-time attacks. Using our framework, we achieve competitive model performance, a significant reduction in model’s size and an improved empirical adversarial robustness without a severe performance degradation, critical in medical image analysis.",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-18523-6_4",
      "scholar_link": "/scholar?hl=en&cites=6071486383723825463",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "ct",
        "pet"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub071",
      "title": "On the pitfalls of deep image segmentation for lightsheet microscopy",
      "authors": "Rami Al-Maskari and Johannes C Paetzold and Izabela Horvath and Ali Erturk",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Fluorescence light sheet microscopy (LSM) of tissue cleared samples enables holistic 3D imaging of the human brain and the full murine body. While this novel imaging method creates high resolution scans and has led to an abundance of high-profile publications in the last 5 years, analysing them is not trivial and comes with complex obstacles. In this paper we present a review and discussion of our groups previous works to present best practices on both animal and human scans and guidelines to overcome these obstacles",
      "url": "https://openreview.net/forum?id=3Krfu84W-Wx",
      "scholar_link": "/scholar?hl=en&cites=9875883160193450499",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "microscopy",
        "segmentation",
        "ct"
      ],
      "primary_category": "microscopy",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub072",
      "title": "Semi-implicit neural solver for time-dependent partial differential equations",
      "authors": "Suprosanna Shit and Ivan Ezhov and Leon Mächler and Jana Lipkova and Johannes C Paetzold and Florian Kofler and Marie Piraud and Bjoern H Menze",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Fast and accurate solutions of time-dependent partial differential equations (PDEs) are of pivotal interest to many research fields, including physics, engineering, and biology. Generally, implicit/semi-implicit schemes are preferred over explicit ones to improve stability and correctness. However, existing semi-implicit methods are usually iterative and employ a general-purpose solver, which may be sub-optimal for a specific class of PDEs. In this paper, we propose a neural solver to learn an optimal iterative scheme in a data-driven fashion for any class of PDEs. Specifically, we modify a single iteration of a semi-implicit solver using a deep neural network. We provide theoretical guarantees for the correctness and convergence of neural solvers analogous to conventional iterative solvers. In addition to the commonly used Dirichlet boundary condition, we adopt a diffuse domain approach to incorporate a diverse type of boundary conditions, e.g., Neumann. We show that the proposed neural solver can go beyond linear PDEs and applies to a class of non-linear PDEs, where the non-linear component is non-stiff. We demonstrate the efficacy of our method on 2D and 3D scenarios. To this end, we show how our model generalizes to parameter settings, which are different from training; and achieves faster convergence than semi-implicit schemes.",
      "url": "https://arxiv.org/abs/2109.01467",
      "scholar_link": "/scholar?hl=en&cites=15330284505573757867",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub073",
      "title": "Suprosanna Shit, Richard McKinley, et al.,“Are we using appropriate segmentation metrics? identifying correlates of human expert perception for cnn training beyond rolling the dice coefficient,”",
      "authors": "Florian Kofler and Ivan Ezhov and Fabian Isensee and Fabian Balsiger and Christoph Berger and Maximilian Koerner and Johannes Paetzold and Hongwei Li",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "",
      "url": "https://scholar.google.com/scholar?cluster=12406973406433716517&hl=en&oi=scholarr",
      "scholar_link": "/scholar?hl=en&cites=12406973406433716517",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "segmentation"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub074",
      "title": "Suprosanna Shit, Richard McKinley, Spyridon Bakas, et al. 2021. Are we using appropriate segmentation metrics? Identifying correlates of human expert perception for CNN training beyond rolling the DICE coefficient",
      "authors": "Florian Kofler and Ivan Ezhov and Fabian Isensee and Christoph Berger and Maximilian Korner and Johannes Paetzold and Hongwei Li",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "",
      "url": "https://scholar.google.com/scholar?cluster=10705767775991842806&hl=en&oi=scholarr",
      "scholar_link": "/scholar?hl=en&cites=10705767775991842806",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "segmentation"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub075",
      "title": "Improving Generalized Zero-Shot Learning for Multi-LabelChest X-ray Classification Using Knowledge Graphs",
      "authors": "Chinmay Prabhakar and Anjany Sekuboyina and Johannes C Paetzold and Hongwei Li and Tamaz Amiranashvili and Jens Kleesiek",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Generalized zero-shot learning (GZSL) aims to develop models that can reliably label classes not encountered during training, while maintaining a good performance on the seen ones. This becomes especially challenging in the realm of multi-label chest X-ray image classification, due to the presence of numerous unknown disease-types and the limited information inherent to x-ray images. In this work, we present a knowledge graph-based approach to GZSL. Our method directly injects the semantic relationships between seen and unseen disease classes by making use of the Unified Medical Language System (UMLS ). Specifically, we use the UMLS as a knowledge base and device a principled approach of parsing and processing it, conditioned on the task at hand. We show that our method matches the labelling performance of the state-of-the-art while outperforming it on unseen classes (AU-ROC 0.68 vs. 0.66). We also demonstrate that embedding the disease-specific knowledge as a graph provides inherent explainability, which allows us to understand the multi-label relation and model decision",
      "url": "https://openreview.net/forum?id=vAxp4zGTIVw",
      "scholar_link": "/scholar?hl=en&cites=16169211827368108369",
      "citations": 2,
      "pdf_link": "",
      "categories": [
        "x-ray",
        "classification",
        "ct"
      ],
      "primary_category": "x-ray",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub077",
      "title": "Modeling the acquisition shift between axial and sagittal MRI for diffusion superresolution to enable axial spine segmentation",
      "authors": "Robert Graf and Hendrik Möller and Julian McGinnis and Sebastian Rühling and Maren Weihrauch and Matan Atad and Suprosanna Shit and Mark Mühlau and Johannes C Paetzold and Daniel Rueckert and Jan Kirschke",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Spine MRIs are usually acquired in highly anisotropic 2D axial or sagittal slices. Vertebra structures are not fully resolved in these images, and multi-image superresolution by aligning scans to pair them is difficult due to partial volume effects and inter-vertebral movement during acquisition. Hence, we propose an unpaired inpainting superresolution algorithm that extrapolates the missing spine structures. We generate synthetic training pairs by multiple degradation functions that model the data shift and acquisition errors between sagittal slices and sagittal views of axial images. Our method employs modeling of the k-space point spread function and the interslice gap. Further, we imitate different MR acquisition challenges like histogram shifts, bias fields, interlace movement artifacts, Gaussian noise, and blur. This enables the training of diffusion-based superresolution models on scaling factors larger than 6 without real paired data. The low z-resolution in axial images prevents existing approaches from separating individual vertebrae instances. By applying this superresolution model to the z-dimension, we can generate images that allow a pre-trained segmentation model to distinguish between vertebrae and enable automatic segmentation and processing of axial images. We experimentally benchmark our method and show that diffusion-based superresolution outperforms state-of-the-art super-resolution models.",
      "url": "https://openreview.net/forum?id=Ywu8wb2wuH",
      "scholar_link": "/scholar?hl=en&cites=13678136796634368387",
      "citations": 1,
      "pdf_link": "",
      "categories": [
        "mri",
        "generative",
        "segmentation",
        "ct",
        "reconstruction"
      ],
      "primary_category": "mri",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub078",
      "title": "Pitfalls of topology-aware image segmentation",
      "authors": "Alexander H Berger and Laurin Lux and Alexander Weers and Martin Menten and Daniel Rueckert and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Topological correctness, i.e., the preservation of structural integrity and specific characteristics of shape, is a fundamental requirement for medical imaging tasks, such as neuron or vessel segmentation. Despite the recent surge in topology-aware methods addressing this challenge, their real-world applicability is hindered by flawed benchmarking practices. In this paper, we identify critical pitfalls in model evaluation that include inadequate connectivity choices, overlooked topological artifacts in ground truth annotations, and inappropriate use of evaluation metrics. Through detailed empirical analysis, we uncover these issues' profound impact on the evaluation and ranking of segmentation methods. Drawing from our findings, we propose a set of actionable recommendations to establish fair and robust evaluation standards for topology-aware medical image segmentation methods.",
      "url": "https://arxiv.org/abs/2412.14619",
      "scholar_link": "/scholar?hl=en&cites=18394470719825634284",
      "citations": 1,
      "pdf_link": "",
      "categories": [
        "topology",
        "segmentation",
        "ct"
      ],
      "primary_category": "topology",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub079",
      "title": "Deep Learning and 3D Imaging Reveal Whole-Body Alterations in Obesity",
      "authors": "Doris Kaltenecker and Izabela Horvath and Rami Al-Maskari and Zeynep Ilgin Kolabas and Ying Chen and Luciano Hoeher and Mihail Todorov and Saketh Kapoor and Mayar Ali and Florian Kofler and Pauline Morigny and Julia Geppert and Denise Jeridi and Carolina Cigankova and Victor Miro Kolenic and Nilsu Gür and Chenchen Pan and Marie Piraud and Daniel Rueckert and Maria Rohm and Farida Hellal and Markus Elsner and Harsharan Singh Bhatia and Bjorn H Menze and Stephan Herzig and Johannes Christian Paetzold and Mauricio Berriel Diaz and Ali Ertürk",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Many diseases, such as obesity, have systemic effects that impact multiple organ systems throughout the body. However, tools for comprehensive, high-resolution analysis of disease-associated changes at the whole-body scale have been lacking. Here, we developed a suite of deep learning-based image analysis algorithms (MouseMapper) and integrated it with tissue clearing and light-sheet microscopy to enable a comprehensive analysis of diseases impacting diverse systems across the mouse body. This approach enables the quantitative analysis of cellular and structural changes across the entire mouse body at unprecedented resolution and scale, including tracking nerves over several centimeters in whole animal bodies. To demonstrate its power, we applied MouseMapper to study nervous and immune systems in high-fat diet induced obesity. We uncovered widespread changes in both immune cell distribution and nerve structures, including alterations in the trigeminal nerve characterized by a reduced number of nerve endings in obese mice. These structural abnormalities were associated with functional deficits of whisker sensing and proteomic changes in the trigeminal ganglion, primarily affecting pathways related to axon growth and the complement system. Additionally, we found heterogeneity in obesity-induced whole-body inflammation across different tissues and organs. Our study demonstrates MouseMapper’s capability to discover and quantify pathological alterations at the whole-body level, offering a powerful approach for investigating the systemic impacts of various diseases.We developed …",
      "url": "https://www.biorxiv.org/content/10.1101/2024.08.18.608300.abstract",
      "scholar_link": "/scholar?hl=en&cites=4925941740956502736",
      "citations": 1,
      "pdf_link": "",
      "categories": [
        "generative",
        "ct",
        "microscopy"
      ],
      "primary_category": "generative",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub082",
      "title": "A Domain-specific Perceptual Metric via Contrastive Self-supervised Representation: Applications on Natural and Medical Images",
      "authors": "Hongwei Bran Li and Chinmay Prabhakar and Suprosanna Shit and Johannes Paetzold and Tamaz Amiranashvili and Jianguo Zhang and Daniel Rueckert and Juan Eugenio Iglesias and Benedikt Wiestler and Bjoern Menze",
      "year": 2022,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Quantifying the perceptual similarity of two images is a long-standing problem in low-level computer vision. The natural image domain commonly relies on supervised learning, e.g., a pre-trained VGG, to obtain a latent representation. However, due to domain shift, pre-trained models from the natural image domain might not apply to other image domains, such as medical imaging. Notably, in medical imaging, evaluating the perceptual similarity is exclusively performed by specialists trained extensively in diverse medical fields. Thus, medical imaging remains devoid of task-specific, objective perceptual measures. This work answers the question: Is it necessary to rely on supervised learning to obtain an effective representation that could measure perceptual similarity, or is self-supervision sufficient? To understand whether recent contrastive self-supervised representation (CSR) may come to the rescue, we start with natural images and systematically evaluate CSR as a metric across numerous contemporary architectures and tasks and compare them with existing methods. We find that in the natural image domain, CSR behaves on par with the supervised one on several perceptual tests as a metric, and in the medical domain, CSR better quantifies perceptual similarity concerning the experts' ratings. We also demonstrate that CSR can significantly improve image quality in two image synthesis tasks. Finally, our extensive results suggest that perceptuality is an emergent property of CSR, which can be adapted to many image domains without requiring annotations.",
      "url": "https://arxiv.org/abs/2212.01577",
      "scholar_link": "/scholar?hl=en&cites=17336646233303235067",
      "citations": 1,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub086",
      "title": "MSSEG-2 new MS lesions detection and segmentation challenge using a data management and processing infrastructure",
      "authors": "Timo Löhr and Johannes C Paetzold and Anjany Sekobouyina and Suprosanna Shit and Ivan Ezhov and Benedikt Wiestler and Bjoern H Menze",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We propose an automatic solution for the MSSEG-2 challenge to detect and segment new multiple sclerosis (MS) lesions in T2-FLAIR magnetic resonance images (MRI). New lesions arising between two time points are one of the most relevant biomarkers for clinical diagnosis and prognosis of MS disease progression. Our method relies on a 3D U-net with data augmentation; it segments all MS lesions for both given FLAIR images. We then subtract the segmentations from both time points and post-process to achieve our new lesion count and segmentation.",
      "url": "https://inria.hal.science/hal-03358968/file/MSSEG2_Challenge_Proceedings.pdf#page=30",
      "scholar_link": "/scholar?hl=en&cites=14616591104372935023",
      "citations": 1,
      "pdf_link": "",
      "categories": [
        "mri",
        "ct",
        "segmentation",
        "detection",
        "classification"
      ],
      "primary_category": "mri",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub087",
      "title": "Skelite: Compact Neural Networks for Efficient Iterative Skeletonization",
      "authors": "Luis D Reyes Vargas and Martin J Menten and Johannes C Paetzold and Nassir Navab and Mohammad Farid Azampour",
      "year": 2025,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Skeletonization extracts thin representations from images that compactly encode their geometry and topology. These representations have become an important topological prior for preserving connectivity in curvilinear structures, aiding medical tasks like vessel segmentation. Existing compatible skeletonization algorithms face significant trade-offs: morphology-based approaches are computationally efficient but prone to frequent breakages, while topology-preserving methods require substantial computational resources. We propose a novel framework for training iterative skeletonization algorithms with a learnable component. The framework leverages synthetic data, task-specific augmentation, and a model distillation strategy to learn compact neural networks that produce thin, connected skeletons with a fully differentiable iterative algorithm. Our method demonstrates a 100 times speedup over topology-constrained algorithms while maintaining high accuracy and generalizing effectively to new domains without fine-tuning. Benchmarking and downstream validation in 2D and 3D tasks demonstrate its computational efficiency and real-world applicability",
      "url": "https://arxiv.org/abs/2503.07369",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "topology",
        "ct",
        "segmentation"
      ],
      "primary_category": "topology",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub088",
      "title": "Interpretable Retinal Disease Prediction Using Biology-Informed Heterogeneous Graph Representations",
      "authors": "Laurin Lux and Alexander H Berger and Maria Romeo Tricas and Alaa E Fayed and Sobha Sivaprasada and Linus Kreitner and Jonas Weidner and Martin J Menten and Daniel Rueckert and Johannes C Paetzold",
      "year": 2025,
      "venue": "arXiv",
      "venue_tag": "arXiv",
      "doi": null,
      "abstract": "Interpretability is crucial to enhance trust in machine learning models for medical diagnostics. However, most state-of-the-art image classifiers based on neural networks are not interpretable. As a result, clinicians often resort to known biomarkers for diagnosis, although biomarker-based classification typically performs worse than large neural networks. This work proposes a method that surpasses the performance of established machine learning models while simultaneously improving prediction interpretability for diabetic retinopathy staging from optical coherence tomography angiography (OCTA) images. Our method is based on a novel biology-informed heterogeneous graph representation that models retinal vessel segments, intercapillary areas, and the foveal avascular zone (FAZ) in a human-interpretable way. This graph representation allows us to frame diabetic retinopathy staging as a graph-level classification task, which we solve using an efficient graph neural network. We benchmark our method against well-established baselines, including classical biomarker-based classifiers, convolutional neural networks (CNNs), and vision transformers. Our model outperforms all baselines on two datasets. Crucially, we use our biology-informed graph to provide explanations of unprecedented detail. Our approach surpasses existing methods in precisely localizing and identifying critical vessels or intercapillary areas. In addition, we give informative and human-interpretable attributions to critical characteristics. Our work contributes to the development of clinical decision-support tools in ophthalmology.",
      "url": "https://arxiv.org/abs/2502.16697",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "classification",
        "ct",
        "gnn"
      ],
      "primary_category": "classification",
      "thumbnail": "images/publications/manual_added/gnn_interp.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub091",
      "title": "SELMA3D challenge: Self-supervised learning for 3D light-sheet microscopy image segmentation",
      "authors": "Ying Chen and Rami Al-Maskari and Izabela Horvath and Mayar Ali and Luciano Höher and Kaiyuan Yang and Zengming Lin and Zhiwei Zhai and Mengzhe Shen and Dejin Xun and Yi Wang and Tony Xu and Maged Goubran and Yunheng Wu and Ali Erturk and Johannes C Paetzold",
      "year": 2025,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Recent innovations in light sheet microscopy, paired with developments in tissue clearing techniques, enable the 3D imaging of large mammalian tissues with cellular resolution. Combined with the progress in large-scale data analysis, driven by deep learning, these innovations empower researchers to rapidly investigate the morphological and functional properties of diverse biological samples. Segmentation, a crucial preliminary step in the analysis process, can be automated using domain-specific deep learning models with expert-level performance. However, these models exhibit high sensitivity to domain shifts, leading to a significant drop in accuracy when applied to data outside their training distribution. To address this limitation, and inspired by the recent success of self-supervised learning in training generalizable models, we organized the SELMA3D Challenge during the MICCAI 2024 conference. SELMA3D provides a vast collection of light-sheet images from cleared mice and human brains, comprising 35 large 3D images-each with over 1000^3 voxels-and 315 annotated small patches for finetuning, preliminary testing and final testing. The dataset encompasses diverse biological structures, including vessel-like and spot-like structures. Five teams participated in all phases of the challenge, and their proposed methods are reviewed in this paper. Quantitative and qualitative results from most participating teams demonstrate that self-supervised learning on large datasets improves segmentation model performance and generalization. We will continue to support and extend SELMA3D as an inaugural MICCAI challenge focused on self …",
      "url": "https://arxiv.org/abs/2501.03880",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "microscopy",
        "segmentation",
        "ct",
        "generative"
      ],
      "primary_category": "microscopy",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub092",
      "title": "FedPID: An Aggregation Method for Federated Learning",
      "authors": "Leon Mächler and Gustav Grimberg and Ivan Ezhov and Manuel Nickel and Suprosanna Shit and David Naccache and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "This paper presents FedPID, our submission to the Federated Tumor Segmentation Challenge 2024 (FETS24). Inspired by FedCostWAvg and FedPIDAvg, our winning contributions to FETS21 and FETS2022, we propose an improved aggregation strategy for federated and collaborative learning. FedCostWAvg is a method that averages results by considering both the number of training samples in each group and how much the cost function decreased in the last round of training. This is similar to how the derivative part of a PID controller works. In FedPIDAvg, we also included the integral part that was missing. Another challenge we faced were vastly differing dataset sizes at each center. We solved this by assuming the sizes follow a Poisson distribution and adjusting the training iterations for each center accordingly. Essentially, this part of the method controls that outliers that require too much training time are less frequently used. Based on these contributions we now adapted FedPIDAvg by changing how the integral part is computed. Instead of integrating the loss function we measure the global drop in cost since the first round.",
      "url": "https://arxiv.org/abs/2411.02152",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub093",
      "title": "Detecting Unforeseen Data Properties with Diffusion Autoencoder Embeddings Using Spine MRI Data",
      "authors": "Robert Graf and Florian Hunecke and Soeren Pohl and Matan Atad and Hendrik Moeller and Sophie Starck and Thomas Kroencke and Stefanie Bette and Fabian Bamberg and Tobias Pischon and Thoralf Niendorf and Carsten Schmidt and Johannes C Paetzold and Daniel Rueckert and Jan S Kirschke",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Deep learning has made significant strides in medical imaging, leveraging the use of large datasets to improve diagnostics and prognostics. However, large datasets often come with inherent errors through subject selection and acquisition. In this paper, we investigate the use of Diffusion Autoencoder (DAE) embeddings for uncovering and understanding data characteristics and biases, including biases for protected variables like sex and data abnormalities indicative of unwanted protocol variations. We use sagittal T2-weighted magnetic resonance (MR) images of the neck, chest, and lumbar region from 11186 German National Cohort (NAKO) participants. We compare DAE embeddings with existing generative models like StyleGAN and Variational Autoencoder. Evaluations on a large-scale dataset consisting of sagittal T2-weighted MR images of three spine regions show that DAE embeddings effectively …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-77610-6_8",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "generative",
        "mri",
        "ct",
        "classification"
      ],
      "primary_category": "generative",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub094",
      "title": "Exploring Graphs as Data Representation for Disease Classification in Ophthalmology",
      "authors": "Laurin Lux and Alexander H Berger and Maria Romeo-Tricas and Martin J Menten and Daniel Rueckert and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Interpretability, particularly in terms of human understandable concepts, is essential for building trust in machine learning models for disease classification. However, state-of-the-art image classifiers exhibit limited interpretability, posing a significant barrier to their acceptance in clinical practice. To address this, our work introduces two graph representations of the retinal vasculature, aiming to bridge the gap between high-performance classifiers and human-understandable interpretability concepts in ophthalmology. We use these graphs with the aim of training graph neural networks (GNNs) for disease staging. First, we formally and experimentally show that GNNs can learn known clinical biomarkers. In that, we show that GNNs can learn human interpretable concepts. Next, we train GNNs for disease staging and study how different aggregation strategies lead the GNN to learn more and less human interpretable …",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-83243-7_5",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "classification",
        "gnn",
        "ct"
      ],
      "primary_category": "classification",
      "thumbnail": "images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub095",
      "title": "Supervised Contrastive Learning for Image-to-Graph Transformers",
      "authors": "Anna Banaszak and Alexander H Berger and Laurin Lux and Suprosanna Shit and Daniel Rueckert and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Image-to-graph transformers can effectively encode image information in graphs but are typically difficult to train and require large annotated datasets. Contrastive learning can increase data efficiency by enhancing feature representations, but existing methods are not applicable to graph labels because they operate on categorical label spaces. In this work, we propose a method enabling supervised contrastive learning for image-to-graph transformers. We introduce two supervised contrastive loss formulations based on graph similarity between label pairs that we approximate using a graph neural network. Our approach avoids tailored data augmentation techniques and can be easily integrated into existing training pipelines. We perform multiple empirical studies showcasing performance improvements across various metrics. ",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-83243-7_1",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct",
        "gnn"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub096",
      "title": "Efficient Betti Matching Enables Topology-Aware 3D Segmentation via Persistent Homology",
      "authors": "Nico Stucki and Vincent Bürgin and Johannes C Paetzold and Ulrich Bauer",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "In this work, we propose an efficient algorithm for the calculation of the Betti matching, which can be used as a loss function to train topology aware segmentation networks. Betti matching loss builds on techniques from topological data analysis, specifically persistent homology. A major challenge is the computational cost of computing persistence barcodes. In response to this challenge, we propose a new, highly optimized implementation of Betti matching, implemented in C++ together with a python interface, which achieves significant speedups compared to the state-of-the-art implementation Cubical Ripser. We use Betti matching 3D to train segmentation networks with the Betti matching loss and demonstrate improved topological correctness of predicted segmentations across several datasets. The source code is available at https://github.com/nstucki/Betti-Matching-3D.",
      "url": "https://arxiv.org/abs/2407.04683",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "topology",
        "segmentation",
        "ct"
      ],
      "primary_category": "topology",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub097",
      "title": "Simplifying deep learning to enhance accessibility of large-scale 3D brain imaging analysis",
      "authors": "Doris Kaltenecker and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We created DELiVR, a deep-learning pipeline for 3D brain-cell mapping that is trained with virtual reality-generated reference annotations. It can be deployed via the user-friendly interface of the open-source software Fiji, which makes the analysis of large-scale 3D brain images widely accessible to scientists without computational expertise.",
      "url": "https://scholar.google.com/scholar?cluster=7733309722599837075&hl=en&oi=scholarr",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "other"
      ],
      "primary_category": "other",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub098",
      "title": "TotalVibeSegmentator: Full Body MRI Segmentation for the NAKO and UK Biobank",
      "authors": "Robert Graf and Paul-Sören Platzek and Evamaria Olga Riedel and Constanze Ramschütz and Sophie Starck and Hendrik Kristian Möller and Matan Atad and Henry Völzke and Robin Bülow and Carsten Oliver Schmidt and Julia Rüdebusch and Matthias Jung and Marco Reisert and Jakob Weiss and Maximilian Löffler and Fabian Bamberg and Bene Wiestler and Johannes C Paetzold and Daniel Rueckert and Jan Stefan Kirschke",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "",
      "url": "https://arxiv.org/abs/2406.00125",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "mri",
        "segmentation"
      ],
      "primary_category": "mri",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub099",
      "title": "Cross-domain and Cross-dimension Learning for Image-to-Graph Transformers",
      "authors": "Alexander H Berger and Laurin Lux and Suprosanna Shit and Ivan Ezhov and Georgios Kaissis and Martin J Menten and Daniel Rueckert and Johannes C Paetzold",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Direct image-to-graph transformation is a challenging task that involves solving object detection and relationship prediction in a single model. Due to this task's complexity, large training datasets are rare in many domains, making the training of deep-learning methods challenging. This data sparsity necessitates transfer learning strategies akin to the state-of-the-art in general computer vision. In this work, we introduce a set of methods enabling cross-domain and cross-dimension learning for image-to-graph transformers. We propose (1) a regularized edge sampling loss to effectively learn object relations in multiple domains with different numbers of edges, (2) a domain adaptation framework for image-to-graph transformers aligning image- and graph-level features from different domains, and (3) a projection function that allows using 2D data for training 3D transformers. We demonstrate our method's utility in cross-domain and cross-dimension experiments, where we utilize labeled data from 2D road networks for simultaneous learning in vastly different target domains. Our method consistently outperforms standard transfer learning and self-supervised pretraining on challenging benchmarks, such as retinal or whole-brain vessel graph extraction.",
      "url": "https://arxiv.org/abs/2403.06601",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "detection",
        "ct"
      ],
      "primary_category": "detection",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub100",
      "title": "Surface Normal Estimation with Transformers",
      "authors": "Barry Shichen Hu and Siyun Liang and Johannes Paetzold and Huy H Nguyen and Isao Echizen and Jiapeng Tang",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We propose the use of a Transformer to accurately predict normals from point clouds with noise and density variations. Previous learning-based methods utilize PointNet variants to explicitly extract multi-scale features at different input scales, then focus on a surface fitting method by which local point cloud neighborhoods are fitted to a geometric surface approximated by either a polynomial function or a multi-layer perceptron (MLP). However, fitting surfaces to fixed-order polynomial functions can suffer from overfitting or underfitting, and learning MLP-represented hyper-surfaces requires pre-generated per-point weights. To avoid these limitations, we first unify the design choices in previous works and then propose a simplified Transformer-based model to extract richer and more robust geometric features for the surface normal estimation task. Through extensive experiments, we demonstrate that our Transformer-based method achieves state-of-the-art performance on both the synthetic shape dataset PCPNet, and the real-world indoor scene dataset SceneNN, exhibiting more noise-resilient behavior and significantly faster inference. Most importantly, we demonstrate that the sophisticated hand-designed modules in existing works are not necessary to excel at the task of surface normal estimation.",
      "url": "https://arxiv.org/abs/2401.05745",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub101",
      "title": "Surface Normal Estimation with Transformers",
      "authors": "Barry Shichen Hu and Siyun Liang and Johannes Paetzold and Huy H Nguyen and Isao Echizen and Jiapeng Tang",
      "year": 2024,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We propose the use of a Transformer to accurately predict normals from point clouds with noise and density variations. Previous learning-based methods utilize PointNet variants to explicitly extract multi-scale features at different input scales, then focus on a surface fitting method by which local point cloud neighborhoods are fitted to a geometric surface approximated by either a polynomial function or a multi-layer perceptron (MLP). However, fitting surfaces to fixed-order polynomial functions can suffer from overfitting or underfitting, and learning MLP-represented hyper-surfaces requires pre-generated per-point weights. To avoid these limitations, we first unify the design choices in previous works and then propose a simplified Transformer-based model to extract richer and more robust geometric features for the surface normal estimation task. Through extensive experiments, we demonstrate that our Transformer …",
      "url": "https://ui.adsabs.harvard.edu/abs/2024arXiv240105745S/abstract",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub102",
      "title": "Retinal Vasculature of Different Diameters and Plexuses Exhibit Distinct Vulnerability to Varying Stages of Diabetic Retinopathy",
      "authors": "Alaa E Fayed and Martin Joseph Menten and Linus Kreitner and Johannes CC Paetzold and Daniel Rueckert and Sherry M Bassily and Ahmed M Hagag and Sobha Sivaprasad",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Purpose: We studied the impact of different stages of diabetic retinopathy (DR) on the vessel densities (VD) of different-sized vessels in the retinal superficial & deep vascular complexes (SVC and DVC) using optical coherence tomography angiography (OCTA) and analyzed the images via deep learning.Methods: In this retrospective, cross-sectional study, 854 eyes of 854 subjects were divided into 5 groups: healthy controls (555 eyes), diabetics with no DR (90 eyes), early DR (mild and moderate non-proliferative diabetic retinopathy (NPDR))(96 eyes), late DR (severe NPDR)(42 eyes) and proliferative DR (PDR)(71 eyes). Only dry maculae were included. OCTA imaging was done using the RTVue Avanti device (Optovue Inc, USA) and the machine-segmented 3x3 mm 2 macular SVC & DVC scans were obtained. VD measurements were extracted using a two-step pipeline. We employed a nnU-Net neural network combined with transfer learning from artificial vessel images to segment the vasculature in fine detail (Fig. 1). The radius of each vessel was determined using the Voreen software. VD for each plexus was calculated and stratified by vessel diameter (< 10μm, 10-20μm,> 20μm). Non-parametric tests were used to assess the differences in VD between groups. P-values were adjusted for multiple comparisons.Results: Overall VD measurements were statistically significantly different between the groups in both the SVC & DVC with a progressively decreasing trend with increasing DR severity (p< 0.001 in both). The largest percentage difference between the healthy and no DR groups was in the< 10μm vessels of the SVC (13.9% lower in …",
      "url": "https://iovs.arvojournals.org/article.aspx?articleid=2790690",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub103",
      "title": "Automated Analysis of Diabetic Retinopathy Using Vessel Segmentation",
      "authors": "Linus Kreitner and Ivan Ezhov¹ and Daniel Rueckert and Johannes C Paetzold",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Recent studies suggest that early stages of diabetic retinopa-thy (DR) can be diagnosed by monitoring vascular changes in the deep vascular complex. In this work, we investigate a novel method for auto-mated DR grading based on ultra-wide optical coherence tomography angiography (UW-OCTA) images. Our work combines OCTA scans with their vessel segmentations, which then serve as inputs to task specific networks for lesion segmentation, image quality assessment and DR grad-ing. For this, we generate synthetic OCTA images to train a segmenta-tion network that can be directly applied on real OCTA data. We test our approach on MICCAI 2022's DR analysis challenge (DRAC). In our experiments, the proposed method performs equally well as the baseline model.",
      "url": "https://books.google.com/books?hl=en&lr=&id=_qjBEAAAQBAJ&oi=fnd&pg=PA16&dq=info:_GL5BYBcJ8sJ:scholar.google.com&ots=GF7g-VuipR&sig=ZLYv8VEDUXd-Lbr38uI3flwx6Ds",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "segmentation",
        "ct"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub104",
      "title": "Whole Brain Vasculature Analysis Using Advanced Learning Models",
      "authors": "Johannes Christian Paetzold",
      "year": 2023,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "The brain's vascular network supplies oxygen to the brain's 86 billion neurons, firmly linking the microvasculature to the neural organization. This thesis reports my work on developing machine learning models to understand brain vessels. At the core of my work are three studies: 1) The first study shows the first deep-learning-based segmentation of the entire brain vasculature. 2) We formulate a novel, topology-preserving loss function with theoretical proofs up to homotopy equivalence. 3) We c...»",
      "url": "https://mediatum.ub.tum.de/1659236",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct",
        "generative",
        "topology",
        "segmentation"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub106",
      "title": "and Segmentation of Aneurysm",
      "authors": "Suprosanna Shit and Ivan Ezhov¹ and Johannes C Paetzold",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "We propose an automatic solution for the CADA 2020 chal-lenge to detect aneurysm from Digital Subtraction Angiography (DSA) images. Our method relies on 3D U-net as the backbone and heavy data augmentation with a carefully chosen loss function. We were able to gen-eralize well using our solution (despite training on a small dataset) that is demonstrated through accurate detection and segmentation on the test data.",
      "url": "https://books.google.com/books?hl=en&lr=&id=KscpEAAAQBAJ&oi=fnd&pg=PA50&dq=info:56fMbYTZWVwJ:scholar.google.com&ots=GEuAc37azK&sig=smyjjT5L58ceZPn_9a-Ums_Aimw",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "segmentation",
        "ct",
        "detection"
      ],
      "primary_category": "segmentation",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub107",
      "title": "Graph Extraction of Peripancreatic Arteries",
      "authors": "Alina Dima and Johannes C Paetzold and Markus Graf and Tristan Lemke and Philipp Raffler and Bjoern Menze and Georgios Kaissis and Rickmer Braren and Daniel Rueckert",
      "year": 2021,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Pancreatic ductal adenocarcinoma (PDAC) is an aggressive cancer with poor prognosis, in which vascular invasion is often to blame for poor operative success. Therefore, understanding the involved vasculature is an important step in building automated methods assisting in pre-operative care. In this work, we extract a comprehensive set of graphs of the peripancreatic vasculature derived from contrast enhanced arterial-phase CT images of the peripancreatic region, together with medically relevant vessel features. Building a more abstract and compact representation of the peripancreatic vasculature is essential in further downstream tasks such as vessel tree labelling, infiltration detection, or classification of anatomical vessel variants.",
      "url": "https://scholar.google.com/scholar?cluster=10460764836633249775&hl=en&oi=scholarr",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct",
        "detection",
        "classification"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub108",
      "title": "Application of Space Borne CO2 and Fluorescence Measurements to Detect Urban CO2 Emissions and Anthropogenic Influence on Vegetation",
      "authors": "Johannes C Paetzold and Jia Chen and Veronika Ruisinger",
      "year": 2017,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "The Orbiting Carbon Observatory 2 (OCO-2) is a NASA satellite mission dedicated to make global, space-based observations of atmospheric, column-averaged carbon dioxide (XCO2). In addition, the OCO-2 also measures Solar Induced Chlorophyll Fluorescence (SIF). In our research we have studied the combination of OCO-2's XCO2 and SIF measurements for numerous urban areas on the different continents. Applying GIS and KML visualization techniques as well as statistical approaches we are able to reliably detect anthropogenic CO2 emissions in CO2 column concentration enhancements over urban areas. Moreover, we detect SIF decreases over urban areas compared to their rural vicinities. We are able to obtain those findings for urban areas on different continents, of diverse sizes, dissimilar topographies and urban constructions. Our statistical analysis finds robust XCO2 enhancements of up to 3 ppm …",
      "url": "https://ui.adsabs.harvard.edu/abs/2017EGUGA..1916986P/abstract",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct",
        "topology"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub109",
      "title": "Total Column CO2 measurements with EM27/SUNs",
      "authors": "JE Franklin and J Chen and TS Jones and JC Paetzold and J Hedelius and H Nguyen and E Gottlieb and J Budney and S Wofsy",
      "year": 2017,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "mediaTUM - Medien- und Publikationsserver mediaTUM Universitätsbibliothek Technische \nUniversität München Logo Benutzer: Gast Login de en Erweiterte Suche mediaTUM \nGesamtbestand Hochschulbibliographie Elektronische Prüfungsarbeiten Open Access \nPublikationen Forschungsdaten TUM.University Press Sammlungen Projekte Einrichtungen \nForschungszentren Hochschulpräsidium Hochschulreferate Partnerschaftliche Einrichtungen \nSchools TUM School of Computation, Information and Technology (44515) Prüfungsarbeiten (3552) \nDepartments (36753) Computer Engineering Computer Science (6905) Electrical Engineering \n(6462) Chip-based Magnetic Sensor Technology (Prof. Becherer) Computational Photonics \n(Prof. Jirauschek) (1072) Control and Manipulation of Microscale Living Objects (Prof. Destgeer) \n(45) Halbleitertechnologie (Prof. Belkin) (255) Heinz Nixdorf-Lehrstuhl für Biomedizinische …",
      "url": "https://mediatum.ub.tum.de/1429817",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub111",
      "title": "Total Column Greenhouse Gas Monitoring in Central Munich: Automation and Measurements",
      "authors": "Jia Chen and Ludwig Heinle and Johannes C Paetzold and Long Le",
      "year": 2016,
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "It is challenging to use in-situ surface measurements of CO2 and CH4 to derive emission fluxes in urban regions. Surface concentrations typically have high variance due to the influence of nearby sources, and they are strongly modulated by mesoscale transport phenomena that are difficult to simulate in atmospheric models. The integrated amount of a tracer through the whole atmosphere is a direct measure of the mass loading of the atmosphere given by emissions. Column measurements are insensitive to vertical redistribution of tracer mass, eg due to growth of the planetary boundary layer, and are also less influenced by nearby point sources, whose emissions are concentrated in a thin layer near the surface. Column observations are more compatible with the scale of atmospheric models and hence provide stronger constraints for inverse modeling. In Munich we are aiming at establishing a regional sensor …",
      "url": "https://ui.adsabs.harvard.edu/abs/2016EGUGA..18.3247C/abstract",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub113",
      "title": "Exploring Graphs as Data Representation",
      "authors": "Laurin Lux and Alexander H Berger and Maria Romeo-Tricas¹ and Martin J Menten and Daniel Rueckert and Johannes C Paetzold",
      "year": "",
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Interpretability, particularly in terms of human understandable concepts, is essential for building trust in machine learning models for disease classification. However, state-of-the-art image classifiers exhibit limited interpretability, posing a significant barrier to their acceptance in clinical practice. To address this, our work introduces two graph representations of the retinal vasculature, aiming to bridge the gap between high-performance classifiers and human-understandable inter-pretability concepts in ophthalmology. We use these graphs with the aim of training graph neural networks (GNNs) for disease staging. First, we formally and experimentally show that GNNs can learn known clinical biomarkers. In that, we show that GNNs can learn human interpretable concepts. Next, we train GNNs for disease staging and study how different aggregation strategies lead the GNN to learn more and less human interpretable features. Finally, we propose a visualization for integrated gradients on graphs, which allows us to identify if GNN models have learned human-understandable representations of the data. The code is available at github. com/luxtu/graphs_in_ophthalmology.",
      "url": "https://books.google.com/books?hl=en&lr=&id=YExLEQAAQBAJ&oi=fnd&pg=PA43&dq=info:-Ai2RTlxkooJ:scholar.google.com&ots=QFeOTuqRLF&sig=KjoFjVj6k7VGtbEjMJGKamIWYMk",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "gnn",
        "classification",
        "ct"
      ],
      "primary_category": "gnn",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub114",
      "title": "Structured Joint Aleatoric and Epistemic Uncertainty for High Dimensional Output Spaces",
      "authors": "Leonhard F Feiner and Manuel Nickel and Laurin Lux and Martin J Menten and Rickmer Braren and Daniel Rueckert and Georgios Kaissis and Johannes C Paetzold",
      "year": "",
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "Uncertainty estimation plays a vital role in enhancing the reliability of deep learning model predictions, especially in scenarios with high-dimensional output spaces. This paper addresses the dual nature of uncertainty — aleatoric and epistemic — focusing on their joint integration in high-dimensional regression tasks. We introduce an approach to approximate joint uncertainty using a low-rank plus diagonal covariance matrix, which preserves essential output correlations while mitigating the computational complexity associated with full covariance matrices. Specifically, our method reduces memory usage and enhances sampling efficiency and log-likelihood calculations. Simultaneously, our representation matches the true posterior better than factorized joint distributions, offering a clear advancement in reliability and explainability for deep learning model predictions. Furthermore, we empirically show that our method can efficiently enhance out of distribution detection in specific applications.",
      "url": "https://openreview.net/forum?id=Ilteh48w7m",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "ct",
        "detection"
      ],
      "primary_category": "ct",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub115",
      "title": "Topologically faithful multi-class segmentation in medical images",
      "authors": "Daniel Rueckert Banaszak and Ulrich Bauer and Johannes C Paetzold",
      "year": "",
      "venue": "MICCAI",
      "venue_tag": "MICCAI",
      "doi": null,
      "abstract": "Topological accuracy in medical image segmentation is a highly important property for downstream applications such as network analysis and flow modeling in vessels or cell counting. Recently, significant methodological advancements have brought well-founded concepts from algebraic topology to binary segmentation. However, these approaches have been underexplored in multi-class segmentation scenarios, where topological errors are common. We propose a general loss function for topologically faithful multi-class segmentation extending the recent Betti matching concept, which is based on induced matchings of persistence barcodes. We project the N-class segmentation problem to N single-class segmentation tasks, which allows us to use 1-parameter persistent homology, making training of neural networks computationally feasible. We validate our method on a comprehensive set of four medical datasets with highly variant topological characteristics. Our loss formulation significantly enhances topological correctness in cardiac, cell, artery-vein, and Circle of Willis segmentation. 7",
      "url": "https://papers.miccai.org/miccai-2024/paper/0582_paper.pdf",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "topology",
        "segmentation",
        "ct"
      ],
      "primary_category": "topology",
      "thumbnail": "images/publications/manual_added/Betti.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub116",
      "title": "MSc Thesis: Contrastive Learning and Generative Models for Cross-Domain Transfer Learning",
      "authors": "Johannes C Paetzold and Alexander Berger",
      "year": "",
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "In this Master thesis we aim to approach the cross-domain transfer learning problem with two powerful methods that help us to bridge the domain gap between source and target domain: contrastive learning [1] and generative models. Specifically, we want to solve the transfer learning problem for the computer vision task of graph extraction from images (eg road network extraction, blood-vessel network extraction, scene graph generation, or pose estimation)[2].",
      "url": "https://aim-lab.io/theses/johannespaetzold/diffusionformer/",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "generative",
        "ct"
      ],
      "primary_category": "generative",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub117",
      "title": "A skeletonization algorithm for gradient-based optimization–supplementary material",
      "authors": "Martin J Menten and Johannes C Paetzold and Veronika A Zimmer and Suprosanna Shit and Ivan Ezhov and Robbie Holland and Monika Probst and Julia A Schnabel and Daniel Rueckert",
      "year": "",
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "DRIVE The widely used DRIVE dataset consists of 40 twodimensional retinal color fundus photographs and matching annotations of the visible blood vessels [9]. We normalize the images to an intensity range between 0 and 1 and crop them to a size of 512× 512 pixel. Then, we divide the dataset into training, validation and testing splits with a ratio of 60% to 20% to 20%.VesSAP The VesSAP dataset contains 24 three-dimensional light-sheet microscopy images of murine brains after tissue clearing, staining, and labeling of the vascular network. It has been made publicly available and has been extensively described by Todorov et al.[10]. We split the 500× 500× 50 voxel large images into non-overlapping patches of size 50× 50× 50. We remove the patches that only contain background. Finally, we split the remaining ones into a training, validation and testing partition with a ratio of 80% to 10% to 10%, while ensuring a subject-wise split. Mandible The mandible dataset consists of 34 matched CT and MR images of the lower head and neck. In all images the mandible bone was outlined by a clinical expert. We resample all images to a resolution of 0.25× 0.25× 0.25 cm3 and subsequently remove all smaller cavities of the segmentation mask by alternatingly applying dilation and erosion operations. For the benchmarking experiments of the skeletonization algorithm we exclusively use the CT images (cf. Section 4.1 of the main paper). For the multimodal registration workflow that incorporates our skeletonization module we use the matched image pairs (cf. Section 4.3 of the main paper).",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/supplemental/Menten_A_Skeletonization_Algorithm_ICCV_2023_supplemental.pdf",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "topology",
        "ct",
        "microscopy",
        "segmentation",
        "registration"
      ],
      "primary_category": "topology",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    },
    {
      "id": "pub118",
      "title": "Supplementary Material for clDice-a Novel Topology-Preserving Loss Function for Tubular Structure Segmentation",
      "authors": "Suprosanna Shit and Johannes C Paetzold and Ivan Ezhov and Anjany Sekuboyina and Alexander Unger and Andrey Zhylka and Josien PW Pluim and Ulrich Bauer and Bjoern H Menze",
      "year": "",
      "venue": "",
      "venue_tag": null,
      "doi": null,
      "abstract": "In addition to our Theorem 1 in the main paper, we are providing intuitive interpretations of clDice from the digital topology perspective. Betti numbers describe and quantify topological differences in algebraic topology. The first three Betti numbers (β0, β1, and β2) comprehensively capture the manifolds appearing in 2D and 3D topological space. Specifically,• β0 represents the number of connected-components,• β1 represents the number of circular holes, and• β2 represents the number of cavities (Only in 3D)",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/supplemental/Shit_clDice_-_A_CVPR_2021_supplemental.pdf",
      "scholar_link": "",
      "citations": 0,
      "pdf_link": "",
      "categories": [
        "topology",
        "ct",
        "segmentation"
      ],
      "primary_category": "topology",
      "thumbnail": "./images/publications/default.png",
      "featured": false,
      "featuredOrder": 999
    }
  ]
}